[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=15", "Precision": 0.3704819277108434, "Recall": 0.3788501026694045, "F1_Score": 0.37461928934010147, "rel_type_metrics": {"Part_of": {"precision": 0.3, "recall": 0.19047619047619047, "f1": 0.23300970873786406}, "Feature_of": {"precision": 0.06896551724137931, "recall": 0.06779661016949153, "f1": 0.06837606837606837}, "Compare": {"precision": 0.26, "recall": 0.34210526315789475, "f1": 0.29545454545454547}, "Used_for": {"precision": 0.3574007220216607, "recall": 0.3714821763602251, "f1": 0.3643054277828887}, "Conjunction": {"precision": 0.5864661654135338, "recall": 0.6341463414634146, "f1": 0.609375}, "Hyponym_of": {"precision": 0.48484848484848486, "recall": 0.47761194029850745, "f1": 0.48120300751879697}, "Evaluate_for": {"precision": 0.3368421052631579, "recall": 0.3516483516483517, "f1": 0.3440860215053763}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-22-22", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=15", "Precision": 0.3616813294232649, "Recall": 0.3798767967145791, "F1_Score": 0.37055583375062595, "rel_type_metrics": {"Conjunction": {"precision": 0.5407407407407407, "recall": 0.5934959349593496, "f1": 0.5658914728682171}, "Part_of": {"precision": 0.34375, "recall": 0.1746031746031746, "f1": 0.23157894736842102}, "Used_for": {"precision": 0.3440677966101695, "recall": 0.3808630393996248, "f1": 0.36153161175422976}, "Hyponym_of": {"precision": 0.4925373134328358, "recall": 0.4925373134328358, "f1": 0.4925373134328358}, "Compare": {"precision": 0.32, "recall": 0.42105263157894735, "f1": 0.3636363636363636}, "Evaluate_for": {"precision": 0.31868131868131866, "recall": 0.31868131868131866, "f1": 0.31868131868131866}, "Feature_of": {"precision": 0.08620689655172414, "recall": 0.0847457627118644, "f1": 0.08547008547008547}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-31-42", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=15", "Precision": 0.3795180722891566, "Recall": 0.38809034907597534, "F1_Score": 0.38375634517766494, "rel_type_metrics": {"Used_for": {"precision": 0.36347197106690776, "recall": 0.3771106941838649, "f1": 0.3701657458563536}, "Feature_of": {"precision": 0.06060606060606061, "recall": 0.06779661016949153, "f1": 0.06400000000000002}, "Evaluate_for": {"precision": 0.3225806451612903, "recall": 0.32967032967032966, "f1": 0.32608695652173914}, "Hyponym_of": {"precision": 0.5076923076923077, "recall": 0.4925373134328358, "f1": 0.5}, "Conjunction": {"precision": 0.6136363636363636, "recall": 0.6585365853658537, "f1": 0.6352941176470588}, "Compare": {"precision": 0.3076923076923077, "recall": 0.42105263157894735, "f1": 0.35555555555555557}, "Part_of": {"precision": 0.38235294117647056, "recall": 0.20634920634920634, "f1": 0.26804123711340205}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-41-08", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}]