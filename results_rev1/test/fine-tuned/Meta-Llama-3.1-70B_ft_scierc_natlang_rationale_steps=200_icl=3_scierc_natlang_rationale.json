[{"Model": "./models/Meta-Llama-3.1-70B_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.03844100373731981, "Recall": 0.07392197125256673, "F1_Score": 0.050579557428872504, "rel_type_metrics": {"Part_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.029227557411273485, "recall": 0.11382113821138211, "f1": 0.046511627906976744}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.04654895666131621, "recall": 0.10881801125703565, "f1": 0.06520517144463181}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-08-07-09-17", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Meta-Llama-3.1-70B_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.05585980284775466, "Recall": 0.052361396303901436, "F1_Score": 0.05405405405405405, "rel_type_metrics": {"Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.08796296296296297, "recall": 0.07129455909943715, "f1": 0.07875647668393781}, "Compare": {"precision": 0.03361344537815126, "recall": 0.21052631578947367, "f1": 0.057971014492753624}, "Hyponym_of": {"precision": 0.03669724770642202, "recall": 0.05970149253731343, "f1": 0.045454545454545456}, "Evaluate_for": {"precision": 0.013513513513513514, "recall": 0.01098901098901099, "f1": 0.012121212121212121}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-08-12-39-02", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Meta-Llama-3.1-70B_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.03984819734345351, "Recall": 0.043121149897330596, "F1_Score": 0.04142011834319526, "rel_type_metrics": {"Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.06584362139917696, "recall": 0.0600375234521576, "f1": 0.06280667320902847}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.009009009009009009, "recall": 0.031746031746031744, "f1": 0.014035087719298246}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0.008298755186721992, "recall": 0.03389830508474576, "f1": 0.013333333333333334}, "Compare": {"precision": 0.08955223880597014, "recall": 0.15789473684210525, "f1": 0.11428571428571428}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-08-19-03-54", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}]