[{"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.1752988047808765, "Recall": 0.19909502262443438, "F1_Score": 0.1864406779661017, "rel_type_metrics": {"Adverse_effect": {"precision": 0.2297650130548303, "recall": 0.19909502262443438, "f1": 0.21333333333333335}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-28-22-39-49", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.16666666666666666, "Recall": 0.18552036199095023, "F1_Score": 0.17558886509635976, "rel_type_metrics": {"Adverse_effect": {"precision": 0.19902912621359223, "recall": 0.18552036199095023, "f1": 0.1920374707259953}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-13-13-19", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.22055674518201285, "Recall": 0.2330316742081448, "F1_Score": 0.22662266226622663, "rel_type_metrics": {"Adverse_effect": {"precision": 0.2594458438287154, "recall": 0.2330316742081448, "f1": 0.24553039332538737}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-13-17-32", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": false, "chat_model": true}]