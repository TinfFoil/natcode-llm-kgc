[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=6", "Precision": 0.36511919698870765, "Recall": 0.29876796714579057, "F1_Score": 0.3286278938452851, "rel_type_metrics": {"Part_of": {"precision": 0.3548387096774194, "recall": 0.1746031746031746, "f1": 0.2340425531914894}, "Evaluate_for": {"precision": 0.29347826086956524, "recall": 0.2967032967032967, "f1": 0.29508196721311475}, "Used_for": {"precision": 0.3624031007751938, "recall": 0.350844277673546, "f1": 0.3565300285986654}, "Conjunction": {"precision": 0.4444444444444444, "recall": 0.2601626016260163, "f1": 0.3282051282051282}, "Compare": {"precision": 0.32558139534883723, "recall": 0.3684210526315789, "f1": 0.34567901234567905}, "Hyponym_of": {"precision": 0.6071428571428571, "recall": 0.2537313432835821, "f1": 0.3578947368421053}, "Feature_of": {"precision": 0.2, "recall": 0.05084745762711865, "f1": 0.08108108108108107}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-28-12", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=6", "Precision": 0.38303341902313626, "Recall": 0.3059548254620123, "F1_Score": 0.3401826484018265, "rel_type_metrics": {"Evaluate_for": {"precision": 0.3132530120481928, "recall": 0.2857142857142857, "f1": 0.2988505747126437}, "Hyponym_of": {"precision": 0.6666666666666666, "recall": 0.3283582089552239, "f1": 0.44000000000000006}, "Conjunction": {"precision": 0.4861111111111111, "recall": 0.2845528455284553, "f1": 0.35897435897435903}, "Compare": {"precision": 0.29545454545454547, "recall": 0.34210526315789475, "f1": 0.3170731707317074}, "Part_of": {"precision": 0.3225806451612903, "recall": 0.15873015873015872, "f1": 0.2127659574468085}, "Feature_of": {"precision": 0.2857142857142857, "recall": 0.06779661016949153, "f1": 0.1095890410958904}, "Used_for": {"precision": 0.37524950099800397, "recall": 0.3527204502814259, "f1": 0.3636363636363636}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-35-58", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=6", "Precision": 0.3619167717528373, "Recall": 0.2946611909650924, "F1_Score": 0.32484436898698354, "rel_type_metrics": {"Hyponym_of": {"precision": 0.6, "recall": 0.26865671641791045, "f1": 0.3711340206185567}, "Part_of": {"precision": 0.4, "recall": 0.19047619047619047, "f1": 0.25806451612903225}, "Compare": {"precision": 0.3488372093023256, "recall": 0.39473684210526316, "f1": 0.3703703703703704}, "Used_for": {"precision": 0.359375, "recall": 0.3452157598499062, "f1": 0.3521531100478469}, "Conjunction": {"precision": 0.4084507042253521, "recall": 0.23577235772357724, "f1": 0.2989690721649485}, "Feature_of": {"precision": 0.25, "recall": 0.06779661016949153, "f1": 0.10666666666666667}, "Evaluate_for": {"precision": 0.27472527472527475, "recall": 0.27472527472527475, "f1": 0.27472527472527475}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-43-32", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}]