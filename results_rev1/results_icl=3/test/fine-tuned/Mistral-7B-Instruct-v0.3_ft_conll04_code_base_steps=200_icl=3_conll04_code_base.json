[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.6279620853080569, "Recall": 0.6511056511056511, "F1_Score": 0.6393244873341375, "rel_type_metrics": {"Organization_based_in": {"precision": 0.6190476190476191, "recall": 0.5416666666666666, "f1": 0.5777777777777778}, "Located_in": {"precision": 0.6352941176470588, "recall": 0.6, "f1": 0.6171428571428571}, "Work_for": {"precision": 0.47619047619047616, "recall": 0.6578947368421053, "f1": 0.5524861878453038}, "Live_in": {"precision": 0.6666666666666666, "recall": 0.6938775510204082, "f1": 0.6799999999999999}, "Kill": {"precision": 0.8913043478260869, "recall": 0.8723404255319149, "f1": 0.8817204301075269}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-27-01-43-54", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.6111111111111112, "Recall": 0.6486486486486487, "F1_Score": 0.629320619785459, "rel_type_metrics": {"Located_in": {"precision": 0.6666666666666666, "recall": 0.6, "f1": 0.631578947368421}, "Kill": {"precision": 0.8541666666666666, "recall": 0.8723404255319149, "f1": 0.8631578947368421}, "Work_for": {"precision": 0.6857142857142857, "recall": 0.631578947368421, "f1": 0.6575342465753424}, "Live_in": {"precision": 0.6542056074766355, "recall": 0.7142857142857143, "f1": 0.6829268292682927}, "Organization_based_in": {"precision": 0.40476190476190477, "recall": 0.53125, "f1": 0.4594594594594595}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-20-49-47", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.618421052631579, "Recall": 0.6928746928746928, "F1_Score": 0.6535341830822712, "rel_type_metrics": {"Kill": {"precision": 0.47126436781609193, "recall": 0.8723404255319149, "f1": 0.6119402985074627}, "Organization_based_in": {"precision": 0.648936170212766, "recall": 0.6354166666666666, "f1": 0.6421052631578947}, "Live_in": {"precision": 0.6052631578947368, "recall": 0.7040816326530612, "f1": 0.6509433962264151}, "Work_for": {"precision": 0.6901408450704225, "recall": 0.6447368421052632, "f1": 0.6666666666666666}, "Located_in": {"precision": 0.6888888888888889, "recall": 0.6888888888888889, "f1": 0.6888888888888889}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-11-05-25", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": true}]