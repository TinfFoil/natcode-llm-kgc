[{"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.140625, "Recall": 0.1832579185520362, "F1_Score": 0.1591355599214145, "rel_type_metrics": {"Adverse_effect": {"precision": 0.1716101694915254, "recall": 0.1832579185520362, "f1": 0.1772428884026258}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-28-18-25-07", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.2026431718061674, "Recall": 0.2081447963800905, "F1_Score": 0.20535714285714285, "rel_type_metrics": {"Adverse_effect": {"precision": 0.24338624338624337, "recall": 0.2081447963800905, "f1": 0.22439024390243903}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-07-06-13", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.2554112554112554, "Recall": 0.2669683257918552, "F1_Score": 0.26106194690265483, "rel_type_metrics": {"Adverse_effect": {"precision": 0.28921568627450983, "recall": 0.2669683257918552, "f1": 0.2776470588235294}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-07-10-48", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}]