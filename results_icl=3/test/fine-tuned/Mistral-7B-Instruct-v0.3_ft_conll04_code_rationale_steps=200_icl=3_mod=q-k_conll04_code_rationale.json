[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_rationale_steps=200_icl=3_mod=q-k", "Precision": 0.4745222929936306, "Recall": 0.36609336609336607, "F1_Score": 0.4133148404993065, "rel_type_metrics": {"Organization_based_in": {"precision": 0.5573770491803278, "recall": 0.3541666666666667, "f1": 0.4331210191082802}, "Kill": {"precision": 0.75, "recall": 0.7659574468085106, "f1": 0.7578947368421053}, "Live_in": {"precision": 0.48214285714285715, "recall": 0.2755102040816326, "f1": 0.3506493506493506}, "Work_for": {"precision": 0.3333333333333333, "recall": 0.42105263157894735, "f1": 0.372093023255814}, "Located_in": {"precision": 0.43478260869565216, "recall": 0.2222222222222222, "f1": 0.29411764705882354}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-18-52", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_rationale_steps=200_icl=3_mod=q-k", "Precision": 0.42718446601941745, "Recall": 0.43243243243243246, "F1_Score": 0.42979242979242976, "rel_type_metrics": {"Work_for": {"precision": 0.4105263157894737, "recall": 0.5131578947368421, "f1": 0.45614035087719296}, "Organization_based_in": {"precision": 0.24390243902439024, "recall": 0.10416666666666667, "f1": 0.145985401459854}, "Live_in": {"precision": 0.5111111111111111, "recall": 0.46938775510204084, "f1": 0.48936170212765956}, "Kill": {"precision": 0.76, "recall": 0.8085106382978723, "f1": 0.7835051546391754}, "Located_in": {"precision": 0.3282442748091603, "recall": 0.4777777777777778, "f1": 0.3891402714932127}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-28-35", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_rationale_steps=200_icl=3_mod=q-k", "Precision": 0.5186721991701245, "Recall": 0.3071253071253071, "F1_Score": 0.38580246913580246, "rel_type_metrics": {"Work_for": {"precision": 0.546875, "recall": 0.4605263157894737, "f1": 0.5}, "Live_in": {"precision": 0.2558139534883721, "recall": 0.11224489795918367, "f1": 0.15602836879432624}, "Located_in": {"precision": 0.2857142857142857, "recall": 0.1111111111111111, "f1": 0.16}, "Kill": {"precision": 0.8571428571428571, "recall": 0.7659574468085106, "f1": 0.8089887640449439}, "Organization_based_in": {"precision": 0.5892857142857143, "recall": 0.34375, "f1": 0.4342105263157895}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-57-02", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}]