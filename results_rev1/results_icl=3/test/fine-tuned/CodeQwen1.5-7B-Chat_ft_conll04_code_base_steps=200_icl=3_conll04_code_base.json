[{"Model": "./models/CodeQwen1.5-7B-Chat_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.49671772428884026, "Recall": 0.5577395577395577, "F1_Score": 0.525462962962963, "rel_type_metrics": {"Work_for": {"precision": 0.37254901960784315, "recall": 0.5, "f1": 0.42696629213483145}, "Live_in": {"precision": 0.5568181818181818, "recall": 0.5, "f1": 0.5268817204301076}, "Located_in": {"precision": 0.3893805309734513, "recall": 0.4888888888888889, "f1": 0.4334975369458128}, "Kill": {"precision": 0.7678571428571429, "recall": 0.9148936170212766, "f1": 0.8349514563106796}, "Organization_based_in": {"precision": 0.5463917525773195, "recall": 0.5520833333333334, "f1": 0.5492227979274611}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-21-41-25", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "./models/CodeQwen1.5-7B-Chat_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.4893162393162393, "Recall": 0.5626535626535627, "F1_Score": 0.5234285714285715, "rel_type_metrics": {"Work_for": {"precision": 0.47619047619047616, "recall": 0.5263157894736842, "f1": 0.5}, "Kill": {"precision": 0.8043478260869565, "recall": 0.7872340425531915, "f1": 0.795698924731183}, "Located_in": {"precision": 0.5227272727272727, "recall": 0.5111111111111111, "f1": 0.5168539325842696}, "Live_in": {"precision": 0.5555555555555556, "recall": 0.5612244897959183, "f1": 0.5583756345177664}, "Organization_based_in": {"precision": 0.33774834437086093, "recall": 0.53125, "f1": 0.4129554655870446}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-11-59-02", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "./models/CodeQwen1.5-7B-Chat_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.48697394789579157, "Recall": 0.597051597051597, "F1_Score": 0.5364238410596027, "rel_type_metrics": {"Organization_based_in": {"precision": 0.3959731543624161, "recall": 0.6145833333333334, "f1": 0.48163265306122455}, "Live_in": {"precision": 0.5, "recall": 0.5816326530612245, "f1": 0.5377358490566037}, "Kill": {"precision": 0.7647058823529411, "recall": 0.8297872340425532, "f1": 0.7959183673469387}, "Located_in": {"precision": 0.4537037037037037, "recall": 0.5444444444444444, "f1": 0.494949494949495}, "Work_for": {"precision": 0.5064935064935064, "recall": 0.5131578947368421, "f1": 0.5098039215686275}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-12-01-09", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": true}]