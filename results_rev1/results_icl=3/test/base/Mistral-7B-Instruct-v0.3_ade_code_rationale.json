[{"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.46808510638297873, "Recall": 0.4479638009049774, "F1_Score": 0.45780346820809253, "rel_type_metrics": {"Adverse_effect": {"precision": 0.5294117647058824, "recall": 0.4479638009049774, "f1": 0.4852941176470588}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-08-28-40", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.3014705882352941, "Recall": 0.27828054298642535, "F1_Score": 0.28941176470588237, "rel_type_metrics": {"Adverse_effect": {"precision": 0.3504273504273504, "recall": 0.27828054298642535, "f1": 0.31021437578814626}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-08-31-49", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.43147208121827413, "Recall": 0.38461538461538464, "F1_Score": 0.40669856459330145, "rel_type_metrics": {"Adverse_effect": {"precision": 0.4748603351955307, "recall": 0.38461538461538464, "f1": 0.42500000000000004}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-08-35-28", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}]