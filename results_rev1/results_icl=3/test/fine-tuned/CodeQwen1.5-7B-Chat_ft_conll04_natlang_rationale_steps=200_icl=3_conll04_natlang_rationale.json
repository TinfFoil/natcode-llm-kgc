[{"Model": "./models/CodeQwen1.5-7B-Chat_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.4092009685230024, "Recall": 0.4152334152334152, "F1_Score": 0.4121951219512195, "rel_type_metrics": {"Located_in": {"precision": 0.4027777777777778, "recall": 0.32222222222222224, "f1": 0.35802469135802467}, "Organization_based_in": {"precision": 0.38372093023255816, "recall": 0.34375, "f1": 0.3626373626373627}, "Kill": {"precision": 0.5833333333333334, "recall": 0.7446808510638298, "f1": 0.6542056074766355}, "Live_in": {"precision": 0.4626865671641791, "recall": 0.3163265306122449, "f1": 0.3757575757575758}, "Work_for": {"precision": 0.3228346456692913, "recall": 0.5394736842105263, "f1": 0.40394088669950734}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-14-35-33", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/CodeQwen1.5-7B-Chat_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.36160714285714285, "Recall": 0.39803439803439805, "F1_Score": 0.37894736842105264, "rel_type_metrics": {"Kill": {"precision": 0.5517241379310345, "recall": 0.6808510638297872, "f1": 0.6095238095238096}, "Live_in": {"precision": 0.45161290322580644, "recall": 0.2857142857142857, "f1": 0.35000000000000003}, "Work_for": {"precision": 0.4583333333333333, "recall": 0.5789473684210527, "f1": 0.5116279069767442}, "Located_in": {"precision": 0.35443037974683544, "recall": 0.3111111111111111, "f1": 0.3313609467455621}, "Organization_based_in": {"precision": 0.2054794520547945, "recall": 0.3125, "f1": 0.24793388429752067}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-01-18-23", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/CodeQwen1.5-7B-Chat_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.3230452674897119, "Recall": 0.3857493857493858, "F1_Score": 0.3516237402015678, "rel_type_metrics": {"Organization_based_in": {"precision": 0.25, "recall": 0.25, "f1": 0.25}, "Live_in": {"precision": 0.4657534246575342, "recall": 0.3469387755102041, "f1": 0.39766081871345027}, "Located_in": {"precision": 0.1656441717791411, "recall": 0.3, "f1": 0.2134387351778656}, "Kill": {"precision": 0.5272727272727272, "recall": 0.6170212765957447, "f1": 0.5686274509803921}, "Work_for": {"precision": 0.45263157894736844, "recall": 0.5657894736842105, "f1": 0.5029239766081872}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-01-19-22", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]