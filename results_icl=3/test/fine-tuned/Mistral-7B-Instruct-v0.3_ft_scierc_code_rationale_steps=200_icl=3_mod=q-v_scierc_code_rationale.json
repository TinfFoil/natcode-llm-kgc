[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=q-v", "Precision": 0.2554278416347382, "Recall": 0.2053388090349076, "F1_Score": 0.22766078542970974, "rel_type_metrics": {"Used_for": {"precision": 0.2578125, "recall": 0.24765478424015008, "f1": 0.25263157894736843}, "Evaluate_for": {"precision": 0.14, "recall": 0.07692307692307693, "f1": 0.09929078014184398}, "Feature_of": {"precision": 0.1111111111111111, "recall": 0.03389830508474576, "f1": 0.05194805194805195}, "Compare": {"precision": 0.37142857142857144, "recall": 0.34210526315789475, "f1": 0.35616438356164387}, "Part_of": {"precision": 0.2, "recall": 0.06349206349206349, "f1": 0.09638554216867469}, "Hyponym_of": {"precision": 0.29545454545454547, "recall": 0.19402985074626866, "f1": 0.23423423423423423}, "Conjunction": {"precision": 0.32222222222222224, "recall": 0.23577235772357724, "f1": 0.27230046948356806}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-18-00-46", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=q-v", "Precision": 0.24937965260545905, "Recall": 0.20636550308008214, "F1_Score": 0.2258426966292135, "rel_type_metrics": {"Hyponym_of": {"precision": 0.25925925925925924, "recall": 0.1044776119402985, "f1": 0.14893617021276595}, "Used_for": {"precision": 0.2607879924953096, "recall": 0.2607879924953096, "f1": 0.2607879924953096}, "Part_of": {"precision": 0.09523809523809523, "recall": 0.06349206349206349, "f1": 0.07619047619047618}, "Feature_of": {"precision": 0.13333333333333333, "recall": 0.03389830508474576, "f1": 0.05405405405405406}, "Evaluate_for": {"precision": 0.1951219512195122, "recall": 0.08791208791208792, "f1": 0.12121212121212123}, "Conjunction": {"precision": 0.2755102040816326, "recall": 0.21951219512195122, "f1": 0.24434389140271492}, "Compare": {"precision": 0.3333333333333333, "recall": 0.3684210526315789, "f1": 0.35}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-18-14-02", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=q-v", "Precision": 0.25493716337522443, "Recall": 0.1457905544147844, "F1_Score": 0.1854996734160679, "rel_type_metrics": {"Compare": {"precision": 0.35294117647058826, "recall": 0.3157894736842105, "f1": 0.33333333333333337}, "Feature_of": {"precision": 0.18181818181818182, "recall": 0.03389830508474576, "f1": 0.05714285714285715}, "Used_for": {"precision": 0.26370757180156656, "recall": 0.1894934333958724, "f1": 0.22052401746724887}, "Conjunction": {"precision": 0.32, "recall": 0.06504065040650407, "f1": 0.10810810810810811}, "Hyponym_of": {"precision": 0.4074074074074074, "recall": 0.16417910447761194, "f1": 0.2340425531914894}, "Part_of": {"precision": 0.07017543859649122, "recall": 0.06349206349206349, "f1": 0.06666666666666667}, "Evaluate_for": {"precision": 0.36363636363636365, "recall": 0.04395604395604396, "f1": 0.0784313725490196}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-18-18-17", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}]