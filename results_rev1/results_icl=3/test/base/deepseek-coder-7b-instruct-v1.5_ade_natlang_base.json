[{"Model": "deepseek-ai/deepseek-coder-7b-instruct-v1.5", "Precision": 0.11661341853035144, "Recall": 0.16515837104072398, "F1_Score": 0.13670411985018727, "rel_type_metrics": {"Adverse_effect": {"precision": 0.36318407960199006, "recall": 0.16515837104072398, "f1": 0.22706065318818042}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-27-01-17-13", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "deepseek-ai/deepseek-coder-7b-instruct-v1.5", "Precision": 0.06506849315068493, "Recall": 0.08597285067873303, "F1_Score": 0.07407407407407406, "rel_type_metrics": {"Adverse_effect": {"precision": 0.18181818181818182, "recall": 0.08597285067873303, "f1": 0.11674347158218128}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-28-20-12-15", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "deepseek-ai/deepseek-coder-7b-instruct-v1.5", "Precision": 0.13687600644122383, "Recall": 0.19230769230769232, "F1_Score": 0.1599247412982126, "rel_type_metrics": {"Adverse_effect": {"precision": 0.3090909090909091, "recall": 0.19230769230769232, "f1": 0.23709902370990238}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-10-04-52", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}]