[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=6", "Precision": 0.39544513457556935, "Recall": 0.3921971252566735, "F1_Score": 0.3938144329896907, "rel_type_metrics": {"Conjunction": {"precision": 0.6260869565217392, "recall": 0.5853658536585366, "f1": 0.6050420168067226}, "Hyponym_of": {"precision": 0.5074626865671642, "recall": 0.5074626865671642, "f1": 0.5074626865671642}, "Part_of": {"precision": 0.24390243902439024, "recall": 0.15873015873015872, "f1": 0.1923076923076923}, "Feature_of": {"precision": 0.07547169811320754, "recall": 0.06779661016949153, "f1": 0.07142857142857142}, "Evaluate_for": {"precision": 0.3404255319148936, "recall": 0.3516483516483517, "f1": 0.34594594594594597}, "Used_for": {"precision": 0.3820840950639854, "recall": 0.3921200750469043, "f1": 0.387037037037037}, "Compare": {"precision": 0.42857142857142855, "recall": 0.5526315789473685, "f1": 0.4827586206896552}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-46-19", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=6", "Precision": 0.3960703205791106, "Recall": 0.3932238193018481, "F1_Score": 0.3946419371458011, "rel_type_metrics": {"Evaluate_for": {"precision": 0.367816091954023, "recall": 0.3516483516483517, "f1": 0.3595505617977528}, "Feature_of": {"precision": 0.06557377049180328, "recall": 0.06779661016949153, "f1": 0.06666666666666668}, "Compare": {"precision": 0.45652173913043476, "recall": 0.5526315789473685, "f1": 0.5}, "Conjunction": {"precision": 0.5772357723577236, "recall": 0.5772357723577236, "f1": 0.5772357723577236}, "Used_for": {"precision": 0.39587242026266417, "recall": 0.39587242026266417, "f1": 0.39587242026266417}, "Hyponym_of": {"precision": 0.5076923076923077, "recall": 0.4925373134328358, "f1": 0.5}, "Part_of": {"precision": 0.21153846153846154, "recall": 0.1746031746031746, "f1": 0.191304347826087}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-53-44", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=6", "Precision": 0.3973305954825462, "Recall": 0.3973305954825462, "F1_Score": 0.3973305954825462, "rel_type_metrics": {"Used_for": {"precision": 0.39928698752228164, "recall": 0.4202626641651032, "f1": 0.4095063985374772}, "Hyponym_of": {"precision": 0.532258064516129, "recall": 0.4925373134328358, "f1": 0.5116279069767442}, "Conjunction": {"precision": 0.5785123966942148, "recall": 0.5691056910569106, "f1": 0.5737704918032785}, "Compare": {"precision": 0.3953488372093023, "recall": 0.4473684210526316, "f1": 0.41975308641975306}, "Evaluate_for": {"precision": 0.3225806451612903, "recall": 0.32967032967032966, "f1": 0.32608695652173914}, "Part_of": {"precision": 0.225, "recall": 0.14285714285714285, "f1": 0.17475728155339804}, "Feature_of": {"precision": 0.07407407407407407, "recall": 0.06779661016949153, "f1": 0.07079646017699115}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-00-40", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}]