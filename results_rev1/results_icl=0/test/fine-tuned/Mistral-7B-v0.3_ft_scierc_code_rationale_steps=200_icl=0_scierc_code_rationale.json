[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=0", "Precision": 0.2534562211981567, "Recall": 0.22587268993839835, "F1_Score": 0.23887079261672092, "rel_type_metrics": {"Feature_of": {"precision": 0.1111111111111111, "recall": 0.01694915254237288, "f1": 0.02941176470588235}, "Compare": {"precision": 0.23076923076923078, "recall": 0.23684210526315788, "f1": 0.23376623376623376}, "Used_for": {"precision": 0.24622356495468278, "recall": 0.3058161350844278, "f1": 0.27280334728033473}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.36666666666666664, "recall": 0.2682926829268293, "f1": 0.30985915492957744}, "Evaluate_for": {"precision": 0.22033898305084745, "recall": 0.14285714285714285, "f1": 0.1733333333333333}, "Part_of": {"precision": 0.125, "recall": 0.015873015873015872, "f1": 0.02816901408450704}}, "n_icl_samples": 0, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-01-14-37", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=0", "Precision": 0.2537485582468281, "Recall": 0.22587268993839835, "F1_Score": 0.2390005431830527, "rel_type_metrics": {"Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.36666666666666664, "recall": 0.2682926829268293, "f1": 0.30985915492957744}, "Evaluate_for": {"precision": 0.23333333333333334, "recall": 0.15384615384615385, "f1": 0.18543046357615894}, "Used_for": {"precision": 0.24508320726172467, "recall": 0.30393996247654786, "f1": 0.271356783919598}, "Compare": {"precision": 0.23684210526315788, "recall": 0.23684210526315788, "f1": 0.23684210526315788}, "Feature_of": {"precision": 0.1111111111111111, "recall": 0.01694915254237288, "f1": 0.02941176470588235}, "Part_of": {"precision": 0.125, "recall": 0.015873015873015872, "f1": 0.02816901408450704}}, "n_icl_samples": 0, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-01-26-54", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=0", "Precision": 0.2491349480968858, "Recall": 0.22176591375770022, "F1_Score": 0.23465507876154265, "rel_type_metrics": {"Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.125, "recall": 0.015873015873015872, "f1": 0.02816901408450704}, "Used_for": {"precision": 0.24471299093655588, "recall": 0.30393996247654786, "f1": 0.2711297071129707}, "Feature_of": {"precision": 0.1111111111111111, "recall": 0.01694915254237288, "f1": 0.02941176470588235}, "Compare": {"precision": 0.23076923076923078, "recall": 0.23684210526315788, "f1": 0.23376623376623376}, "Evaluate_for": {"precision": 0.22807017543859648, "recall": 0.14285714285714285, "f1": 0.17567567567567569}, "Conjunction": {"precision": 0.32967032967032966, "recall": 0.24390243902439024, "f1": 0.28037383177570097}}, "n_icl_samples": 0, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-01-39-45", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]