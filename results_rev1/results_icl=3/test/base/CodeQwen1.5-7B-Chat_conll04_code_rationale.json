[{"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.07542579075425791, "Recall": 0.15233415233415235, "F1_Score": 0.10089503661513427, "rel_type_metrics": {"Located_in": {"precision": 0.10810810810810811, "recall": 0.3111111111111111, "f1": 0.16045845272206305}, "Kill": {"precision": 0.1346153846153846, "recall": 0.2978723404255319, "f1": 0.18543046357615894}, "Organization_based_in": {"precision": 0.038461538461538464, "recall": 0.020833333333333332, "f1": 0.02702702702702703}, "Live_in": {"precision": 0.06428571428571428, "recall": 0.09183673469387756, "f1": 0.07563025210084033}, "Work_for": {"precision": 0.072, "recall": 0.11842105263157894, "f1": 0.08955223880597016}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-18-34-05", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.09865470852017937, "Recall": 0.16216216216216217, "F1_Score": 0.12267657992565055, "rel_type_metrics": {"Organization_based_in": {"precision": 0.0784313725490196, "recall": 0.041666666666666664, "f1": 0.05442176870748299}, "Located_in": {"precision": 0.09166666666666666, "recall": 0.12222222222222222, "f1": 0.10476190476190475}, "Live_in": {"precision": 0.14189189189189189, "recall": 0.21428571428571427, "f1": 0.17073170731707316}, "Work_for": {"precision": 0.12631578947368421, "recall": 0.15789473684210525, "f1": 0.14035087719298245}, "Kill": {"precision": 0.11764705882352941, "recall": 0.3829787234042553, "f1": 0.17999999999999997}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-07-18-20", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.06553398058252427, "Recall": 0.13267813267813267, "F1_Score": 0.08773354995938261, "rel_type_metrics": {"Live_in": {"precision": 0.06474820143884892, "recall": 0.09183673469387756, "f1": 0.0759493670886076}, "Work_for": {"precision": 0.07526881720430108, "recall": 0.09210526315789473, "f1": 0.08284023668639053}, "Kill": {"precision": 0.15476190476190477, "recall": 0.2765957446808511, "f1": 0.1984732824427481}, "Located_in": {"precision": 0.12121212121212122, "recall": 0.2222222222222222, "f1": 0.1568627450980392}, "Organization_based_in": {"precision": 0.0199203187250996, "recall": 0.052083333333333336, "f1": 0.028818443804034578}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-07-27-51", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}]