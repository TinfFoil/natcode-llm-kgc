[{"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_rationale_steps=200_icl=12", "Precision": 0.6599496221662469, "Recall": 0.6437346437346437, "F1_Score": 0.6517412935323382, "rel_type_metrics": {"Located_in": {"precision": 0.6224489795918368, "recall": 0.6777777777777778, "f1": 0.6489361702127661}, "Organization_based_in": {"precision": 0.6527777777777778, "recall": 0.4895833333333333, "f1": 0.5595238095238094}, "Work_for": {"precision": 0.6935483870967742, "recall": 0.5657894736842105, "f1": 0.6231884057971016}, "Kill": {"precision": 0.640625, "recall": 0.8723404255319149, "f1": 0.7387387387387387}, "Live_in": {"precision": 0.7070707070707071, "recall": 0.7142857142857143, "f1": 0.7106598984771574}}, "n_icl_samples": 12, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-18-18-58-49", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_rationale_steps=200_icl=12", "Precision": 0.6458852867830424, "Recall": 0.6363636363636364, "F1_Score": 0.641089108910891, "rel_type_metrics": {"Organization_based_in": {"precision": 0.6, "recall": 0.53125, "f1": 0.5635359116022098}, "Work_for": {"precision": 0.6666666666666666, "recall": 0.5263157894736842, "f1": 0.5882352941176471}, "Located_in": {"precision": 0.5480769230769231, "recall": 0.6333333333333333, "f1": 0.5876288659793815}, "Kill": {"precision": 0.8235294117647058, "recall": 0.8936170212765957, "f1": 0.8571428571428571}, "Live_in": {"precision": 0.696969696969697, "recall": 0.7040816326530612, "f1": 0.7005076142131981}}, "n_icl_samples": 12, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-18-19-06-16", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_rationale_steps=200_icl=12", "Precision": 0.6395061728395062, "Recall": 0.6363636363636364, "F1_Score": 0.6379310344827587, "rel_type_metrics": {"Located_in": {"precision": 0.59375, "recall": 0.6333333333333333, "f1": 0.6129032258064516}, "Live_in": {"precision": 0.7040816326530612, "recall": 0.7040816326530612, "f1": 0.7040816326530612}, "Kill": {"precision": 0.8076923076923077, "recall": 0.8936170212765957, "f1": 0.8484848484848485}, "Work_for": {"precision": 0.5432098765432098, "recall": 0.5789473684210527, "f1": 0.5605095541401274}, "Organization_based_in": {"precision": 0.618421052631579, "recall": 0.4895833333333333, "f1": 0.5465116279069767}}, "n_icl_samples": 12, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-18-21-11-57", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]