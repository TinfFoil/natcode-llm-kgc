[{"Model": "unsloth/Meta-Llama-3.1-8B-Instruct", "Precision": 0.18840579710144928, "Recall": 0.03194103194103194, "F1_Score": 0.054621848739495805, "rel_type_metrics": {"Work_for": {"precision": 0.4, "recall": 0.05263157894736842, "f1": 0.09302325581395349}, "Located_in": {"precision": 0.23076923076923078, "recall": 0.03333333333333333, "f1": 0.05825242718446602}, "Organization_based_in": {"precision": 0, "recall": 0.0, "f1": 0}, "Live_in": {"precision": 0.025, "recall": 0.01020408163265306, "f1": 0.014492753623188404}, "Kill": {"precision": 0.8333333333333334, "recall": 0.10638297872340426, "f1": 0.18867924528301885}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-27-00-08-21", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-8B-Instruct", "Precision": 0.21266968325791855, "Recall": 0.11547911547911548, "F1_Score": 0.1496815286624204, "rel_type_metrics": {"Kill": {"precision": 0.13432835820895522, "recall": 0.19148936170212766, "f1": 0.15789473684210525}, "Organization_based_in": {"precision": 0.25, "recall": 0.020833333333333332, "f1": 0.038461538461538464}, "Located_in": {"precision": 0.23529411764705882, "recall": 0.17777777777777778, "f1": 0.20253164556962028}, "Work_for": {"precision": 0.35555555555555557, "recall": 0.21052631578947367, "f1": 0.2644628099173553}, "Live_in": {"precision": 0.16666666666666666, "recall": 0.04081632653061224, "f1": 0.06557377049180327}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-18-59-56", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-8B-Instruct", "Precision": 0.12162162162162163, "Recall": 0.044226044226044224, "F1_Score": 0.06486486486486485, "rel_type_metrics": {"Live_in": {"precision": 0.06666666666666667, "recall": 0.01020408163265306, "f1": 0.017699115044247787}, "Kill": {"precision": 0.5, "recall": 0.10638297872340426, "f1": 0.17543859649122806}, "Located_in": {"precision": 0.06382978723404255, "recall": 0.06666666666666667, "f1": 0.06521739130434781}, "Organization_based_in": {"precision": 0, "recall": 0.0, "f1": 0}, "Work_for": {"precision": 0.20689655172413793, "recall": 0.07894736842105263, "f1": 0.11428571428571428}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-08-11-17", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}]