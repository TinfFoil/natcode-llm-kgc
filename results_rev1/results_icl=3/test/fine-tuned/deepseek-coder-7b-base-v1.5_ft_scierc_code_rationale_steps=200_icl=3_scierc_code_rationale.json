[{"Model": "./models/deepseek-coder-7b-base-v1.5_ft_scierc_code_rationale_steps=200_icl=3", "Precision": 0.2392586352148273, "Recall": 0.2915811088295688, "F1_Score": 0.26284127718648775, "rel_type_metrics": {"Conjunction": {"precision": 0.3384615384615385, "recall": 0.35772357723577236, "f1": 0.34782608695652173}, "Part_of": {"precision": 0.1724137931034483, "recall": 0.07936507936507936, "f1": 0.10869565217391304}, "Used_for": {"precision": 0.2327909887359199, "recall": 0.34896810506566606, "f1": 0.2792792792792793}, "Hyponym_of": {"precision": 0.23404255319148937, "recall": 0.16417910447761194, "f1": 0.19298245614035087}, "Compare": {"precision": 0.2765957446808511, "recall": 0.34210526315789475, "f1": 0.3058823529411765}, "Evaluate_for": {"precision": 0.24719101123595505, "recall": 0.24175824175824176, "f1": 0.24444444444444446}, "Feature_of": {"precision": 0.06521739130434782, "recall": 0.05084745762711865, "f1": 0.05714285714285715}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-26-22-39-03", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/deepseek-coder-7b-base-v1.5_ft_scierc_code_rationale_steps=200_icl=3", "Precision": 0.20314735336194564, "Recall": 0.2915811088295688, "F1_Score": 0.23946037099494097, "rel_type_metrics": {"Used_for": {"precision": 0.18311195445920303, "recall": 0.3621013133208255, "f1": 0.2432262129804663}, "Part_of": {"precision": 0.09523809523809523, "recall": 0.031746031746031744, "f1": 0.047619047619047616}, "Compare": {"precision": 0.34146341463414637, "recall": 0.3684210526315789, "f1": 0.35443037974683544}, "Conjunction": {"precision": 0.3442622950819672, "recall": 0.34146341463414637, "f1": 0.34285714285714286}, "Evaluate_for": {"precision": 0.2159090909090909, "recall": 0.2087912087912088, "f1": 0.2122905027932961}, "Hyponym_of": {"precision": 0.36666666666666664, "recall": 0.16417910447761194, "f1": 0.22680412371134023}, "Feature_of": {"precision": 0.07142857142857142, "recall": 0.05084745762711865, "f1": 0.05940594059405941}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-28-16-33-48", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/deepseek-coder-7b-base-v1.5_ft_scierc_code_rationale_steps=200_icl=3", "Precision": 0.2514395393474088, "Recall": 0.26899383983572894, "F1_Score": 0.25992063492063494, "rel_type_metrics": {"Used_for": {"precision": 0.25, "recall": 0.3339587242026266, "f1": 0.2859437751004016}, "Hyponym_of": {"precision": 0.23333333333333334, "recall": 0.208955223880597, "f1": 0.2204724409448819}, "Evaluate_for": {"precision": 0.2, "recall": 0.1978021978021978, "f1": 0.19889502762430936}, "Compare": {"precision": 0.26666666666666666, "recall": 0.3157894736842105, "f1": 0.2891566265060241}, "Feature_of": {"precision": 0.045454545454545456, "recall": 0.01694915254237288, "f1": 0.02469135802469136}, "Part_of": {"precision": 0.17647058823529413, "recall": 0.047619047619047616, "f1": 0.075}, "Conjunction": {"precision": 0.375, "recall": 0.2926829268292683, "f1": 0.32876712328767116}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-04-23-05", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]