[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=9", "Precision": 0.34906695938529086, "Recall": 0.3264887063655031, "F1_Score": 0.3374005305039788, "rel_type_metrics": {"Conjunction": {"precision": 0.3364485981308411, "recall": 0.2926829268292683, "f1": 0.31304347826086953}, "Part_of": {"precision": 0.29411764705882354, "recall": 0.15873015873015872, "f1": 0.20618556701030927}, "Evaluate_for": {"precision": 0.3229166666666667, "recall": 0.34065934065934067, "f1": 0.3315508021390375}, "Hyponym_of": {"precision": 0.5952380952380952, "recall": 0.373134328358209, "f1": 0.4587155963302752}, "Feature_of": {"precision": 0.15789473684210525, "recall": 0.05084745762711865, "f1": 0.07692307692307693}, "Compare": {"precision": 0.3181818181818182, "recall": 0.3684210526315789, "f1": 0.3414634146341463}, "Used_for": {"precision": 0.3503521126760563, "recall": 0.37335834896810505, "f1": 0.36148955495004537}}, "n_icl_samples": 9, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-31-16", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=9", "Precision": 0.34950385887541346, "Recall": 0.32546201232032856, "F1_Score": 0.3370547581073897, "rel_type_metrics": {"Used_for": {"precision": 0.3430127041742287, "recall": 0.3545966228893058, "f1": 0.34870848708487084}, "Conjunction": {"precision": 0.43478260869565216, "recall": 0.3252032520325203, "f1": 0.37209302325581395}, "Evaluate_for": {"precision": 0.2698412698412698, "recall": 0.37362637362637363, "f1": 0.3133640552995392}, "Hyponym_of": {"precision": 0.6756756756756757, "recall": 0.373134328358209, "f1": 0.4807692307692308}, "Feature_of": {"precision": 0.14285714285714285, "recall": 0.05084745762711865, "f1": 0.07500000000000001}, "Compare": {"precision": 0.32608695652173914, "recall": 0.39473684210526316, "f1": 0.35714285714285715}, "Part_of": {"precision": 0.3235294117647059, "recall": 0.1746031746031746, "f1": 0.2268041237113402}}, "n_icl_samples": 9, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-40-40", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=9", "Precision": 0.35714285714285715, "Recall": 0.32854209445585214, "F1_Score": 0.3422459893048128, "rel_type_metrics": {"Feature_of": {"precision": 0.1875, "recall": 0.05084745762711865, "f1": 0.08}, "Hyponym_of": {"precision": 0.5681818181818182, "recall": 0.373134328358209, "f1": 0.45045045045045046}, "Part_of": {"precision": 0.28205128205128205, "recall": 0.1746031746031746, "f1": 0.2156862745098039}, "Compare": {"precision": 0.34782608695652173, "recall": 0.42105263157894735, "f1": 0.380952380952381}, "Used_for": {"precision": 0.3585951940850277, "recall": 0.36397748592870544, "f1": 0.3612662942271881}, "Evaluate_for": {"precision": 0.28703703703703703, "recall": 0.34065934065934067, "f1": 0.3115577889447236}, "Conjunction": {"precision": 0.39603960396039606, "recall": 0.3252032520325203, "f1": 0.3571428571428571}}, "n_icl_samples": 9, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-49-54", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}]