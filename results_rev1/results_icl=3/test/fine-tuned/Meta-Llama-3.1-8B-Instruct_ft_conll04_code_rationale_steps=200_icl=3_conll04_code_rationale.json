[{"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_conll04_code_rationale_steps=200_icl=3", "Precision": 0.4021543985637343, "Recall": 0.5503685503685504, "F1_Score": 0.4647302904564316, "rel_type_metrics": {"Organization_based_in": {"precision": 0.27071823204419887, "recall": 0.5104166666666666, "f1": 0.35379061371841153}, "Live_in": {"precision": 0.42857142857142855, "recall": 0.4897959183673469, "f1": 0.45714285714285713}, "Work_for": {"precision": 0.559322033898305, "recall": 0.4342105263157895, "f1": 0.4888888888888889}, "Located_in": {"precision": 0.34838709677419355, "recall": 0.6, "f1": 0.4408163265306122}, "Kill": {"precision": 0.8, "recall": 0.851063829787234, "f1": 0.8247422680412372}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-26-23-45-50", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_conll04_code_rationale_steps=200_icl=3", "Precision": 0.40384615384615385, "Recall": 0.5675675675675675, "F1_Score": 0.47191011235955055, "rel_type_metrics": {"Work_for": {"precision": 0.6119402985074627, "recall": 0.5394736842105263, "f1": 0.5734265734265734}, "Located_in": {"precision": 0.34838709677419355, "recall": 0.6, "f1": 0.4408163265306122}, "Organization_based_in": {"precision": 0.40336134453781514, "recall": 0.5, "f1": 0.44651162790697674}, "Kill": {"precision": 0.8367346938775511, "recall": 0.8723404255319149, "f1": 0.8541666666666667}, "Live_in": {"precision": 0.25824175824175827, "recall": 0.47959183673469385, "f1": 0.33571428571428574}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-18-13-16", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_conll04_code_rationale_steps=200_icl=3", "Precision": 0.40298507462686567, "Recall": 0.5307125307125307, "F1_Score": 0.4581124072110286, "rel_type_metrics": {"Located_in": {"precision": 0.3923076923076923, "recall": 0.5666666666666667, "f1": 0.4636363636363636}, "Live_in": {"precision": 0.23979591836734693, "recall": 0.47959183673469385, "f1": 0.3197278911564626}, "Work_for": {"precision": 0.631578947368421, "recall": 0.47368421052631576, "f1": 0.5413533834586466}, "Organization_based_in": {"precision": 0.42857142857142855, "recall": 0.4375, "f1": 0.43298969072164945}, "Kill": {"precision": 0.7272727272727273, "recall": 0.851063829787234, "f1": 0.7843137254901961}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-06-58-09", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}]