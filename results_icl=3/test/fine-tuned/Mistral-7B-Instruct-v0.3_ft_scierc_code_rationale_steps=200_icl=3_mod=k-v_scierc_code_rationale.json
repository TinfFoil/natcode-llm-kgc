[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=k-v", "Precision": 0.23754152823920266, "Recall": 0.14681724845995894, "F1_Score": 0.1814720812182741, "rel_type_metrics": {"Evaluate_for": {"precision": 0.2222222222222222, "recall": 0.04395604395604396, "f1": 0.07339449541284404}, "Hyponym_of": {"precision": 0.2, "recall": 0.07462686567164178, "f1": 0.10869565217391304}, "Compare": {"precision": 0.22727272727272727, "recall": 0.2631578947368421, "f1": 0.24390243902439024}, "Feature_of": {"precision": 0.16666666666666666, "recall": 0.03389830508474576, "f1": 0.056338028169014086}, "Used_for": {"precision": 0.23908045977011494, "recall": 0.1951219512195122, "f1": 0.21487603305785125}, "Conjunction": {"precision": 0.358974358974359, "recall": 0.11382113821138211, "f1": 0.1728395061728395}, "Part_of": {"precision": 0.21052631578947367, "recall": 0.06349206349206349, "f1": 0.0975609756097561}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-18-33-14", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=k-v", "Precision": 0.26282051282051283, "Recall": 0.16837782340862423, "F1_Score": 0.20525657071339173, "rel_type_metrics": {"Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.42424242424242425, "recall": 0.11382113821138211, "f1": 0.17948717948717946}, "Hyponym_of": {"precision": 0.25, "recall": 0.07462686567164178, "f1": 0.11494252873563218}, "Compare": {"precision": 0.2926829268292683, "recall": 0.3157894736842105, "f1": 0.3037974683544304}, "Part_of": {"precision": 0.0625, "recall": 0.015873015873015872, "f1": 0.02531645569620253}, "Evaluate_for": {"precision": 0.23809523809523808, "recall": 0.054945054945054944, "f1": 0.08928571428571429}, "Used_for": {"precision": 0.2673684210526316, "recall": 0.23827392120075047, "f1": 0.25198412698412703}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-18-41-05", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=k-v", "Precision": 0.25, "Recall": 0.1437371663244353, "F1_Score": 0.18252933507170793, "rel_type_metrics": {"Hyponym_of": {"precision": 0.11764705882352941, "recall": 0.029850746268656716, "f1": 0.047619047619047616}, "Conjunction": {"precision": 0.35714285714285715, "recall": 0.16260162601626016, "f1": 0.22346368715083798}, "Used_for": {"precision": 0.2625, "recall": 0.19699812382739212, "f1": 0.22508038585209003}, "Part_of": {"precision": 0.08333333333333333, "recall": 0.015873015873015872, "f1": 0.02666666666666667}, "Compare": {"precision": 0.23684210526315788, "recall": 0.23684210526315788, "f1": 0.23684210526315788}, "Evaluate_for": {"precision": 0.08333333333333333, "recall": 0.01098901098901099, "f1": 0.01941747572815534}, "Feature_of": {"precision": 0.15384615384615385, "recall": 0.03389830508474576, "f1": 0.05555555555555555}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-18-46-40", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}]