[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=6", "Precision": 0.3319371727748691, "Recall": 0.32546201232032856, "F1_Score": 0.3286677034733022, "rel_type_metrics": {"Part_of": {"precision": 0.11688311688311688, "recall": 0.14285714285714285, "f1": 0.1285714285714286}, "Used_for": {"precision": 0.3392857142857143, "recall": 0.32082551594746717, "f1": 0.32979749276759884}, "Compare": {"precision": 0.36, "recall": 0.47368421052631576, "f1": 0.40909090909090906}, "Hyponym_of": {"precision": 0.4878048780487805, "recall": 0.29850746268656714, "f1": 0.3703703703703703}, "Evaluate_for": {"precision": 0.3106796116504854, "recall": 0.3516483516483517, "f1": 0.3298969072164949}, "Conjunction": {"precision": 0.42483660130718953, "recall": 0.5284552845528455, "f1": 0.4710144927536232}, "Feature_of": {"precision": 0.07407407407407407, "recall": 0.03389830508474576, "f1": 0.046511627906976744}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-21-20-55", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=6", "Precision": 0.34543454345434543, "Recall": 0.32238193018480493, "F1_Score": 0.33351035581518856, "rel_type_metrics": {"Evaluate_for": {"precision": 0.2857142857142857, "recall": 0.32967032967032966, "f1": 0.3061224489795918}, "Compare": {"precision": 0.3469387755102041, "recall": 0.4473684210526316, "f1": 0.39080459770114945}, "Feature_of": {"precision": 0.034482758620689655, "recall": 0.01694915254237288, "f1": 0.022727272727272728}, "Part_of": {"precision": 0.1518987341772152, "recall": 0.19047619047619047, "f1": 0.16901408450704225}, "Conjunction": {"precision": 0.4172661870503597, "recall": 0.4715447154471545, "f1": 0.4427480916030535}, "Used_for": {"precision": 0.37259100642398285, "recall": 0.32645403377110693, "f1": 0.348}, "Hyponym_of": {"precision": 0.5365853658536586, "recall": 0.3283582089552239, "f1": 0.40740740740740744}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-21-36-20", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=6", "Precision": 0.3439153439153439, "Recall": 0.3336755646817248, "F1_Score": 0.3387180823345492, "rel_type_metrics": {"Used_for": {"precision": 0.3790322580645161, "recall": 0.3527204502814259, "f1": 0.36540330417881434}, "Part_of": {"precision": 0.13043478260869565, "recall": 0.19047619047619047, "f1": 0.15483870967741933}, "Evaluate_for": {"precision": 0.2777777777777778, "recall": 0.32967032967032966, "f1": 0.3015075376884422}, "Compare": {"precision": 0.40425531914893614, "recall": 0.5, "f1": 0.44705882352941173}, "Feature_of": {"precision": 0.06896551724137931, "recall": 0.03389830508474576, "f1": 0.045454545454545456}, "Conjunction": {"precision": 0.4117647058823529, "recall": 0.45528455284552843, "f1": 0.4324324324324324}, "Hyponym_of": {"precision": 0.4864864864864865, "recall": 0.26865671641791045, "f1": 0.3461538461538462}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-21-51-35", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]