[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=9", "Precision": 0.3951011714589989, "Recall": 0.3809034907597536, "F1_Score": 0.3878724516466283, "rel_type_metrics": {"Conjunction": {"precision": 0.5826086956521739, "recall": 0.5447154471544715, "f1": 0.5630252100840336}, "Part_of": {"precision": 0.20754716981132076, "recall": 0.1746031746031746, "f1": 0.1896551724137931}, "Compare": {"precision": 0.3191489361702128, "recall": 0.39473684210526316, "f1": 0.3529411764705882}, "Evaluate_for": {"precision": 0.38372093023255816, "recall": 0.3626373626373626, "f1": 0.37288135593220334}, "Used_for": {"precision": 0.4, "recall": 0.39399624765478425, "f1": 0.39697542533081287}, "Feature_of": {"precision": 0.07407407407407407, "recall": 0.06779661016949153, "f1": 0.07079646017699115}, "Hyponym_of": {"precision": 0.543859649122807, "recall": 0.4626865671641791, "f1": 0.5}}, "n_icl_samples": 9, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-02-07", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=9", "Precision": 0.3756558237145855, "Recall": 0.3675564681724846, "F1_Score": 0.3715620134924754, "rel_type_metrics": {"Hyponym_of": {"precision": 0.4444444444444444, "recall": 0.417910447761194, "f1": 0.43076923076923074}, "Part_of": {"precision": 0.19230769230769232, "recall": 0.15873015873015872, "f1": 0.17391304347826086}, "Evaluate_for": {"precision": 0.4342105263157895, "recall": 0.3626373626373626, "f1": 0.39520958083832336}, "Feature_of": {"precision": 0.10204081632653061, "recall": 0.0847457627118644, "f1": 0.09259259259259259}, "Compare": {"precision": 0.375, "recall": 0.47368421052631576, "f1": 0.4186046511627907}, "Conjunction": {"precision": 0.5350877192982456, "recall": 0.4959349593495935, "f1": 0.5147679324894514}, "Used_for": {"precision": 0.3697632058287796, "recall": 0.3808630393996248, "f1": 0.37523105360443626}}, "n_icl_samples": 9, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-10-15", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_base_steps=200_icl=9", "Precision": 0.38461538461538464, "Recall": 0.36960985626283366, "F1_Score": 0.3769633507853403, "rel_type_metrics": {"Used_for": {"precision": 0.3761638733705773, "recall": 0.3789868667917448, "f1": 0.37757009345794396}, "Hyponym_of": {"precision": 0.509090909090909, "recall": 0.417910447761194, "f1": 0.4590163934426229}, "Conjunction": {"precision": 0.543859649122807, "recall": 0.5040650406504065, "f1": 0.5232067510548524}, "Part_of": {"precision": 0.2558139534883721, "recall": 0.1746031746031746, "f1": 0.20754716981132076}, "Feature_of": {"precision": 0.125, "recall": 0.1016949152542373, "f1": 0.11214953271028037}, "Compare": {"precision": 0.3695652173913043, "recall": 0.4473684210526316, "f1": 0.40476190476190477}, "Evaluate_for": {"precision": 0.37362637362637363, "recall": 0.37362637362637363, "f1": 0.37362637362637363}}, "n_icl_samples": 9, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-23-17-23", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}]