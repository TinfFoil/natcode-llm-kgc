[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_base_steps=200_icl=6", "Precision": 0.38590956887486855, "Recall": 0.37679671457905545, "F1_Score": 0.3812987012987013, "rel_type_metrics": {"Conjunction": {"precision": 0.5565217391304348, "recall": 0.5203252032520326, "f1": 0.5378151260504203}, "Evaluate_for": {"precision": 0.3854166666666667, "recall": 0.4065934065934066, "f1": 0.39572192513368987}, "Feature_of": {"precision": 0.07936507936507936, "recall": 0.0847457627118644, "f1": 0.08196721311475409}, "Hyponym_of": {"precision": 0.6170212765957447, "recall": 0.43283582089552236, "f1": 0.5087719298245613}, "Part_of": {"precision": 0.37142857142857144, "recall": 0.20634920634920634, "f1": 0.2653061224489796}, "Compare": {"precision": 0.36585365853658536, "recall": 0.39473684210526316, "f1": 0.37974683544303794}, "Used_for": {"precision": 0.3695652173913043, "recall": 0.3827392120075047, "f1": 0.376036866359447}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-11-17", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_base_steps=200_icl=6", "Precision": 0.37706611570247933, "Recall": 0.37474332648870634, "F1_Score": 0.3759011328527292, "rel_type_metrics": {"Part_of": {"precision": 0.30952380952380953, "recall": 0.20634920634920634, "f1": 0.24761904761904763}, "Evaluate_for": {"precision": 0.3541666666666667, "recall": 0.37362637362637363, "f1": 0.3636363636363636}, "Compare": {"precision": 0.3125, "recall": 0.39473684210526316, "f1": 0.3488372093023256}, "Conjunction": {"precision": 0.5555555555555556, "recall": 0.5284552845528455, "f1": 0.5416666666666666}, "Feature_of": {"precision": 0.0847457627118644, "recall": 0.0847457627118644, "f1": 0.0847457627118644}, "Used_for": {"precision": 0.37050359712230213, "recall": 0.38649155722326456, "f1": 0.37832874196510563}, "Hyponym_of": {"precision": 0.574468085106383, "recall": 0.40298507462686567, "f1": 0.4736842105263158}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-15-22", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_base_steps=200_icl=6", "Precision": 0.37995824634655534, "Recall": 0.3737166324435318, "F1_Score": 0.3768115942028986, "rel_type_metrics": {"Conjunction": {"precision": 0.559322033898305, "recall": 0.5365853658536586, "f1": 0.5477178423236515}, "Feature_of": {"precision": 0.08333333333333333, "recall": 0.0847457627118644, "f1": 0.08403361344537816}, "Compare": {"precision": 0.38461538461538464, "recall": 0.39473684210526316, "f1": 0.38961038961038963}, "Part_of": {"precision": 0.34146341463414637, "recall": 0.2222222222222222, "f1": 0.2692307692307692}, "Hyponym_of": {"precision": 0.54, "recall": 0.40298507462686567, "f1": 0.4615384615384615}, "Used_for": {"precision": 0.3686131386861314, "recall": 0.3789868667917448, "f1": 0.3737280296022201}, "Evaluate_for": {"precision": 0.3431372549019608, "recall": 0.38461538461538464, "f1": 0.36269430051813467}}, "n_icl_samples": 6, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-19-10", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": false}]