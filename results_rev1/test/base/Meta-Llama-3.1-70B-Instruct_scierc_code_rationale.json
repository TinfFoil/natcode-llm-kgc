[{"Model": "unsloth/Meta-Llama-3.1-70B-Instruct", "Precision": 0.06272401433691756, "Recall": 0.07186858316221766, "F1_Score": 0.06698564593301434, "rel_type_metrics": {"Conjunction": {"precision": 0.5, "recall": 0.008130081300813009, "f1": 0.016}, "Compare": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0.022857142857142857, "recall": 0.06779661016949153, "f1": 0.034188034188034185}, "Evaluate_for": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.11373390557939914, "recall": 0.09943714821763602, "f1": 0.1061061061061061}, "Hyponym_of": {"precision": 0.022727272727272728, "recall": 0.029850746268656716, "f1": 0.02580645161290323}, "Part_of": {"precision": 0.028901734104046242, "recall": 0.15873015873015872, "f1": 0.0488997555012225}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-11-18-40-56", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-70B-Instruct", "Precision": 0.09375, "Recall": 0.08932238193018481, "F1_Score": 0.09148264984227128, "rel_type_metrics": {"Evaluate_for": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.027649769585253458, "recall": 0.09523809523809523, "f1": 0.04285714285714286}, "Used_for": {"precision": 0.12295081967213115, "recall": 0.14071294559099437, "f1": 0.13123359580052493}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0.16666666666666666, "recall": 0.15789473684210525, "f1": 0.16216216216216214}, "Hyponym_of": {"precision": 0.0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-11-19-28-31", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-70B-Instruct", "Precision": 0.08970099667774087, "Recall": 0.11088295687885011, "F1_Score": 0.09917355371900828, "rel_type_metrics": {"Hyponym_of": {"precision": 0.11428571428571428, "recall": 0.11940298507462686, "f1": 0.11678832116788321}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0.01680672268907563, "recall": 0.06779661016949153, "f1": 0.026936026936026935}, "Part_of": {"precision": 0.0611353711790393, "recall": 0.2222222222222222, "f1": 0.0958904109589041}, "Used_for": {"precision": 0.12312312312312312, "recall": 0.15384615384615385, "f1": 0.13678065054211844}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-11-20-27-24", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": false, "chat_model": true}]