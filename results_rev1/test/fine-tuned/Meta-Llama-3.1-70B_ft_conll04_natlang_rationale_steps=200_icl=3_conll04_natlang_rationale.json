[{"Model": "./models/Meta-Llama-3.1-70B_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.12564543889845095, "Recall": 0.17936117936117937, "F1_Score": 0.14777327935222673, "rel_type_metrics": {"Live_in": {"precision": 0.125, "recall": 0.01020408163265306, "f1": 0.018867924528301883}, "Work_for": {"precision": 0.10714285714285714, "recall": 0.23684210526315788, "f1": 0.14754098360655737}, "Located_in": {"precision": 0.23529411764705882, "recall": 0.08888888888888889, "f1": 0.12903225806451613}, "Organization_based_in": {"precision": 0.1464968152866242, "recall": 0.23958333333333334, "f1": 0.18181818181818182}, "Kill": {"precision": 0.25555555555555554, "recall": 0.48936170212765956, "f1": 0.3357664233576642}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-07-14-25-19", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Meta-Llama-3.1-70B_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.04769475357710652, "Recall": 0.07371007371007371, "F1_Score": 0.05791505791505792, "rel_type_metrics": {"Organization_based_in": {"precision": 0, "recall": 0.0, "f1": 0}, "Kill": {"precision": 0.45454545454545453, "recall": 0.10638297872340426, "f1": 0.17241379310344826}, "Live_in": {"precision": 0.037209302325581395, "recall": 0.08163265306122448, "f1": 0.051118210862619806}, "Work_for": {"precision": 0.11038961038961038, "recall": 0.2236842105263158, "f1": 0.14782608695652172}, "Located_in": {"precision": 0.0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-07-18-47-52", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Meta-Llama-3.1-70B_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.11181434599156118, "Recall": 0.13022113022113022, "F1_Score": 0.12031782065834279, "rel_type_metrics": {"Located_in": {"precision": 0.15384615384615385, "recall": 0.08888888888888889, "f1": 0.11267605633802817}, "Organization_based_in": {"precision": 0.13513513513513514, "recall": 0.20833333333333334, "f1": 0.1639344262295082}, "Live_in": {"precision": 0.10218978102189781, "recall": 0.14285714285714285, "f1": 0.11914893617021277}, "Work_for": {"precision": 0.11235955056179775, "recall": 0.13157894736842105, "f1": 0.12121212121212122}, "Kill": {"precision": 1.0, "recall": 0.02127659574468085, "f1": 0.04166666666666667}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-08-00-04-18", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}]