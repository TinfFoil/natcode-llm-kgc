[{"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.01661631419939577, "Recall": 0.022587268993839837, "F1_Score": 0.019147084421235857, "rel_type_metrics": {"Conjunction": {"precision": 0.05970149253731343, "recall": 0.032520325203252036, "f1": 0.042105263157894736}, "Part_of": {"precision": 0.16666666666666666, "recall": 0.047619047619047616, "f1": 0.07407407407407407}, "Used_for": {"precision": 0.06222222222222222, "recall": 0.02626641651031895, "f1": 0.036939313984168866}, "Feature_of": {"precision": 0.013333333333333334, "recall": 0.01694915254237288, "f1": 0.01492537313432836}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-10-58-45", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.030146425495262703, "Recall": 0.03593429158110883, "F1_Score": 0.03278688524590164, "rel_type_metrics": {"Conjunction": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.125, "recall": 0.047619047619047616, "f1": 0.06896551724137931}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.09523809523809523, "recall": 0.0600375234521576, "f1": 0.07364787111622555}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-11-00-07", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.01683816651075772, "Recall": 0.018480492813141684, "F1_Score": 0.01762114537444934, "rel_type_metrics": {"Used_for": {"precision": 0.07547169811320754, "recall": 0.0225140712945591, "f1": 0.034682080924855495}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.04477611940298507, "recall": 0.09523809523809523, "f1": 0.06091370558375635}, "Conjunction": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-11-01-25", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}]