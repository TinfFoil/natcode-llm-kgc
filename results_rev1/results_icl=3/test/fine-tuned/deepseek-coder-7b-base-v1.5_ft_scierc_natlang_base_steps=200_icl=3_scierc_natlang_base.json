[{"Model": "./models/deepseek-coder-7b-base-v1.5_ft_scierc_natlang_base_steps=200_icl=3", "Precision": 0.28849407783417935, "Recall": 0.35010266940451745, "F1_Score": 0.31632653061224486, "rel_type_metrics": {"Conjunction": {"precision": 0.47794117647058826, "recall": 0.5284552845528455, "f1": 0.5019305019305019}, "Hyponym_of": {"precision": 0.30985915492957744, "recall": 0.3283582089552239, "f1": 0.3188405797101449}, "Used_for": {"precision": 0.29142011834319526, "recall": 0.3696060037523452, "f1": 0.32588916459884204}, "Evaluate_for": {"precision": 0.28888888888888886, "recall": 0.2857142857142857, "f1": 0.287292817679558}, "Compare": {"precision": 0.32653061224489793, "recall": 0.42105263157894735, "f1": 0.367816091954023}, "Feature_of": {"precision": 0.038461538461538464, "recall": 0.06779661016949153, "f1": 0.049079754601226995}, "Part_of": {"precision": 0.19642857142857142, "recall": 0.1746031746031746, "f1": 0.1848739495798319}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-27-00-53-55", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": false}, {"Model": "./models/deepseek-coder-7b-base-v1.5_ft_scierc_natlang_base_steps=200_icl=3", "Precision": 0.31486611265004616, "Recall": 0.35010266940451745, "F1_Score": 0.3315508021390374, "rel_type_metrics": {"Used_for": {"precision": 0.3222591362126246, "recall": 0.36397748592870544, "f1": 0.34185022026431716}, "Conjunction": {"precision": 0.4888888888888889, "recall": 0.5365853658536586, "f1": 0.5116279069767442}, "Evaluate_for": {"precision": 0.2903225806451613, "recall": 0.2967032967032967, "f1": 0.29347826086956524}, "Hyponym_of": {"precision": 0.3424657534246575, "recall": 0.373134328358209, "f1": 0.35714285714285715}, "Compare": {"precision": 0.3488372093023256, "recall": 0.39473684210526316, "f1": 0.3703703703703704}, "Feature_of": {"precision": 0.031914893617021274, "recall": 0.05084745762711865, "f1": 0.03921568627450981}, "Part_of": {"precision": 0.2558139534883721, "recall": 0.1746031746031746, "f1": 0.20754716981132076}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-28-19-44-33", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": false}, {"Model": "./models/deepseek-coder-7b-base-v1.5_ft_scierc_natlang_base_steps=200_icl=3", "Precision": 0.3118181818181818, "Recall": 0.3521560574948665, "F1_Score": 0.33076181292189005, "rel_type_metrics": {"Hyponym_of": {"precision": 0.2857142857142857, "recall": 0.3283582089552239, "f1": 0.3055555555555556}, "Compare": {"precision": 0.36363636363636365, "recall": 0.42105263157894735, "f1": 0.3902439024390244}, "Conjunction": {"precision": 0.4621212121212121, "recall": 0.4959349593495935, "f1": 0.4784313725490196}, "Part_of": {"precision": 0.3142857142857143, "recall": 0.1746031746031746, "f1": 0.22448979591836732}, "Feature_of": {"precision": 0.043010752688172046, "recall": 0.06779661016949153, "f1": 0.052631578947368425}, "Used_for": {"precision": 0.32063492063492066, "recall": 0.3789868667917448, "f1": 0.3473774720550301}, "Evaluate_for": {"precision": 0.30337078651685395, "recall": 0.2967032967032967, "f1": 0.3}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-09-25-37", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": false}]