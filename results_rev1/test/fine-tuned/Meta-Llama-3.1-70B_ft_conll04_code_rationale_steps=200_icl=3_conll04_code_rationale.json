[{"Model": "./models/Meta-Llama-3.1-70B_ft_conll04_code_rationale_steps=200_icl=3", "Precision": 0.22674418604651161, "Recall": 0.28746928746928746, "F1_Score": 0.2535211267605634, "rel_type_metrics": {"Located_in": {"precision": 0.18309859154929578, "recall": 0.28888888888888886, "f1": 0.22413793103448276}, "Kill": {"precision": 0.24096385542168675, "recall": 0.425531914893617, "f1": 0.30769230769230765}, "Organization_based_in": {"precision": 0.34545454545454546, "recall": 0.19791666666666666, "f1": 0.25165562913907286}, "Work_for": {"precision": 0.2672413793103448, "recall": 0.40789473684210525, "f1": 0.3229166666666667}, "Live_in": {"precision": 0.1794871794871795, "recall": 0.21428571428571427, "f1": 0.1953488372093023}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-11-00-39-30", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Meta-Llama-3.1-70B_ft_conll04_code_rationale_steps=200_icl=3", "Precision": 0.14, "Recall": 0.2751842751842752, "F1_Score": 0.1855840927920464, "rel_type_metrics": {"Live_in": {"precision": 0.1693548387096774, "recall": 0.21428571428571427, "f1": 0.18918918918918917}, "Located_in": {"precision": 0.1937984496124031, "recall": 0.2777777777777778, "f1": 0.228310502283105}, "Kill": {"precision": 0.38181818181818183, "recall": 0.44680851063829785, "f1": 0.4117647058823529}, "Organization_based_in": {"precision": 0.04979253112033195, "recall": 0.125, "f1": 0.0712166172106825}, "Work_for": {"precision": 0.13360323886639677, "recall": 0.4342105263157895, "f1": 0.2043343653250774}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-11-03-21-51", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Meta-Llama-3.1-70B_ft_conll04_code_rationale_steps=200_icl=3", "Precision": 0.1417624521072797, "Recall": 0.18181818181818182, "F1_Score": 0.15931108719052745, "rel_type_metrics": {"Kill": {"precision": 0.42857142857142855, "recall": 0.3191489361702128, "f1": 0.36585365853658536}, "Work_for": {"precision": 0.20408163265306123, "recall": 0.2631578947368421, "f1": 0.22988505747126436}, "Organization_based_in": {"precision": 0.15, "recall": 0.03125, "f1": 0.05172413793103448}, "Located_in": {"precision": 0.10891089108910891, "recall": 0.12222222222222222, "f1": 0.11518324607329843}, "Live_in": {"precision": 0.09578544061302682, "recall": 0.25510204081632654, "f1": 0.1392757660167131}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-11-04-32-42", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]