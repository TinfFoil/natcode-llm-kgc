[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_rationale_steps=200_icl=3_mod=v", "Precision": 0.6254416961130742, "Recall": 0.4348894348894349, "F1_Score": 0.5130434782608696, "rel_type_metrics": {"Work_for": {"precision": 0.5138888888888888, "recall": 0.4868421052631579, "f1": 0.5}, "Kill": {"precision": 0.8409090909090909, "recall": 0.7872340425531915, "f1": 0.8131868131868133}, "Live_in": {"precision": 0.7076923076923077, "recall": 0.46938775510204084, "f1": 0.5644171779141105}, "Organization_based_in": {"precision": 0.8484848484848485, "recall": 0.2916666666666667, "f1": 0.434108527131783}, "Located_in": {"precision": 0.42028985507246375, "recall": 0.32222222222222224, "f1": 0.36477987421383645}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-19-11-28", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_rationale_steps=200_icl=3_mod=v", "Precision": 0.5918367346938775, "Recall": 0.35626535626535627, "F1_Score": 0.4447852760736196, "rel_type_metrics": {"Organization_based_in": {"precision": 0.5609756097560976, "recall": 0.23958333333333334, "f1": 0.33576642335766427}, "Located_in": {"precision": 0.4482758620689655, "recall": 0.28888888888888886, "f1": 0.35135135135135137}, "Live_in": {"precision": 0.6896551724137931, "recall": 0.40816326530612246, "f1": 0.5128205128205129}, "Kill": {"precision": 0.7142857142857143, "recall": 0.3191489361702128, "f1": 0.4411764705882353}, "Work_for": {"precision": 0.6119402985074627, "recall": 0.5394736842105263, "f1": 0.5734265734265734}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-19-19-25", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_code_rationale_steps=200_icl=3_mod=v", "Precision": 0.6321070234113713, "Recall": 0.4643734643734644, "F1_Score": 0.5354107648725211, "rel_type_metrics": {"Kill": {"precision": 0.7142857142857143, "recall": 0.7446808510638298, "f1": 0.7291666666666666}, "Organization_based_in": {"precision": 0.6964285714285714, "recall": 0.40625, "f1": 0.5131578947368421}, "Work_for": {"precision": 0.6111111111111112, "recall": 0.5789473684210527, "f1": 0.5945945945945946}, "Live_in": {"precision": 0.6349206349206349, "recall": 0.40816326530612246, "f1": 0.49689440993788825}, "Located_in": {"precision": 0.5535714285714286, "recall": 0.34444444444444444, "f1": 0.4246575342465754}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-19-24-44", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}]