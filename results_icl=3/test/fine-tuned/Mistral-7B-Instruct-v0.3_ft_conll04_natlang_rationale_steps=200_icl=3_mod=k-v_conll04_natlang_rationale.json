[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_rationale_steps=200_icl=3_mod=k-v", "Precision": 0.5555555555555556, "Recall": 0.515970515970516, "F1_Score": 0.535031847133758, "rel_type_metrics": {"Organization_based_in": {"precision": 0.5473684210526316, "recall": 0.5416666666666666, "f1": 0.544502617801047}, "Work_for": {"precision": 0.5964912280701754, "recall": 0.4473684210526316, "f1": 0.5112781954887219}, "Live_in": {"precision": 0.504950495049505, "recall": 0.5204081632653061, "f1": 0.5125628140703518}, "Located_in": {"precision": 0.6567164179104478, "recall": 0.4888888888888889, "f1": 0.5605095541401275}, "Kill": {"precision": 0.5087719298245614, "recall": 0.6170212765957447, "f1": 0.5576923076923077}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-17-23-53", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_rationale_steps=200_icl=3_mod=k-v", "Precision": 0.5340599455040872, "Recall": 0.48157248157248156, "F1_Score": 0.5064599483204134, "rel_type_metrics": {"Kill": {"precision": 0.5370370370370371, "recall": 0.6170212765957447, "f1": 0.5742574257425743}, "Live_in": {"precision": 0.5833333333333334, "recall": 0.5, "f1": 0.5384615384615384}, "Work_for": {"precision": 0.449438202247191, "recall": 0.5263157894736842, "f1": 0.48484848484848486}, "Organization_based_in": {"precision": 0.5694444444444444, "recall": 0.4270833333333333, "f1": 0.4880952380952381}, "Located_in": {"precision": 0.5873015873015873, "recall": 0.4111111111111111, "f1": 0.48366013071895425}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-17-39-17", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_rationale_steps=200_icl=3_mod=k-v", "Precision": 0.4691689008042895, "Recall": 0.42997542997543, "F1_Score": 0.4487179487179487, "rel_type_metrics": {"Live_in": {"precision": 0.5443037974683544, "recall": 0.4387755102040816, "f1": 0.4858757062146893}, "Organization_based_in": {"precision": 0.5283018867924528, "recall": 0.2916666666666667, "f1": 0.3758389261744967}, "Kill": {"precision": 0.4383561643835616, "recall": 0.6808510638297872, "f1": 0.5333333333333332}, "Located_in": {"precision": 0.42857142857142855, "recall": 0.3333333333333333, "f1": 0.375}, "Work_for": {"precision": 0.4772727272727273, "recall": 0.5526315789473685, "f1": 0.5121951219512196}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-17-56-07", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]