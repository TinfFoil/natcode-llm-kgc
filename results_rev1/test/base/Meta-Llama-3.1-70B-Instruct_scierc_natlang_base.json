[{"Model": "unsloth/Meta-Llama-3.1-70B-Instruct", "Precision": 0.07714016933207903, "Recall": 0.08418891170431211, "F1_Score": 0.08051055473735887, "rel_type_metrics": {"Compare": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0.08571428571428572, "recall": 0.03296703296703297, "f1": 0.04761904761904762}, "Part_of": {"precision": 0.1111111111111111, "recall": 0.015873015873015872, "f1": 0.027777777777777776}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.17647058823529413, "recall": 0.1294559099437148, "f1": 0.14935064935064932}, "Conjunction": {"precision": 0.16666666666666666, "recall": 0.07317073170731707, "f1": 0.1016949152542373}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-12-00-48-48", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-70B-Instruct", "Precision": 0.07939508506616257, "Recall": 0.08624229979466119, "F1_Score": 0.08267716535433071, "rel_type_metrics": {"Used_for": {"precision": 0.16625916870415647, "recall": 0.1275797373358349, "f1": 0.14437367303609341}, "Conjunction": {"precision": 0.1111111111111111, "recall": 0.032520325203252036, "f1": 0.050314465408805034}, "Hyponym_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.061224489795918366, "recall": 0.19047619047619047, "f1": 0.09266409266409266}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-12-01-12-08", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-70B-Instruct", "Precision": 0.06616961789375582, "Recall": 0.0728952772073922, "F1_Score": 0.06936980947728383, "rel_type_metrics": {"Compare": {"precision": 0.1095890410958904, "recall": 0.21052631578947367, "f1": 0.14414414414414414}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0.011904761904761904, "recall": 0.01694915254237288, "f1": 0.013986013986013986}, "Used_for": {"precision": 0.1945392491467577, "recall": 0.10694183864915573, "f1": 0.13801452784503632}, "Part_of": {"precision": 0.05263157894736842, "recall": 0.07936507936507936, "f1": 0.06329113924050633}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-12-01-33-16", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}]