[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_natlang_rationale_steps=200_icl=3_mod=q", "Precision": 0.2229299363057325, "Recall": 0.21560574948665298, "F1_Score": 0.21920668058455117, "rel_type_metrics": {"Used_for": {"precision": 0.26904376012965964, "recall": 0.31144465290806755, "f1": 0.288695652173913}, "Conjunction": {"precision": 0.3333333333333333, "recall": 0.13821138211382114, "f1": 0.19540229885057472}, "Evaluate_for": {"precision": 0.1326530612244898, "recall": 0.14285714285714285, "f1": 0.1375661375661376}, "Part_of": {"precision": 0.14285714285714285, "recall": 0.06349206349206349, "f1": 0.0879120879120879}, "Compare": {"precision": 0.1956521739130435, "recall": 0.23684210526315788, "f1": 0.21428571428571427}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 1.0, "recall": 0.01694915254237288, "f1": 0.03333333333333333}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-17-20-04", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_natlang_rationale_steps=200_icl=3_mod=q", "Precision": 0.10467706013363029, "Recall": 0.09650924024640657, "F1_Score": 0.10042735042735042, "rel_type_metrics": {"Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0.14285714285714285, "recall": 0.054945054945054944, "f1": 0.07936507936507936}, "Used_for": {"precision": 0.20348837209302326, "recall": 0.13133208255159476, "f1": 0.1596351197263398}, "Part_of": {"precision": 0.09090909090909091, "recall": 0.015873015873015872, "f1": 0.027027027027027025}, "Conjunction": {"precision": 0.3684210526315789, "recall": 0.11382113821138211, "f1": 0.17391304347826084}, "Compare": {"precision": 0.17391304347826086, "recall": 0.10526315789473684, "f1": 0.13114754098360656}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-17-28-43", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_natlang_rationale_steps=200_icl=3_mod=q", "Precision": 0.20927601809954752, "Recall": 0.18993839835728954, "F1_Score": 0.1991388589881593, "rel_type_metrics": {"Part_of": {"precision": 0.14814814814814814, "recall": 0.06349206349206349, "f1": 0.08888888888888888}, "Hyponym_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.3047619047619048, "recall": 0.2601626016260163, "f1": 0.2807017543859649}, "Used_for": {"precision": 0.21630615640599002, "recall": 0.24390243902439024, "f1": 0.2292768959435626}, "Evaluate_for": {"precision": 0.2, "recall": 0.12087912087912088, "f1": 0.1506849315068493}, "Compare": {"precision": 0.175, "recall": 0.18421052631578946, "f1": 0.1794871794871795}, "Feature_of": {"precision": 0.3333333333333333, "recall": 0.01694915254237288, "f1": 0.03225806451612903}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-17-38-56", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]