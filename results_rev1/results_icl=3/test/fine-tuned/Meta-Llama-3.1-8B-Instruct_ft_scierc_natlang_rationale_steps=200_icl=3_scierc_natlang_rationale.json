[{"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.1986754966887417, "Recall": 0.12320328542094455, "F1_Score": 0.1520912547528517, "rel_type_metrics": {"Evaluate_for": {"precision": 0.5, "recall": 0.04395604395604396, "f1": 0.08080808080808081}, "Part_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0.5, "recall": 0.13432835820895522, "f1": 0.21176470588235297}, "Used_for": {"precision": 0.2735294117647059, "recall": 0.17448405253283303, "f1": 0.21305841924398627}, "Conjunction": {"precision": 0.36, "recall": 0.07317073170731707, "f1": 0.12162162162162161}, "Compare": {"precision": 0.38461538461538464, "recall": 0.13157894736842105, "f1": 0.196078431372549}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-26-21-23-27", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.1804949053857351, "Recall": 0.1273100616016427, "F1_Score": 0.14930764599638774, "rel_type_metrics": {"Conjunction": {"precision": 0.41379310344827586, "recall": 0.0975609756097561, "f1": 0.15789473684210525}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.5, "recall": 0.047619047619047616, "f1": 0.08695652173913042}, "Hyponym_of": {"precision": 0.39285714285714285, "recall": 0.16417910447761194, "f1": 0.23157894736842108}, "Evaluate_for": {"precision": 0.4117647058823529, "recall": 0.07692307692307693, "f1": 0.12962962962962962}, "Used_for": {"precision": 0.256797583081571, "recall": 0.15947467166979362, "f1": 0.19675925925925927}, "Compare": {"precision": 0.5, "recall": 0.15789473684210525, "f1": 0.23999999999999996}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-28-15-06-11", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.14520958083832336, "Recall": 0.09958932238193019, "F1_Score": 0.11814859926918392, "rel_type_metrics": {"Compare": {"precision": 0.4444444444444444, "recall": 0.10526315789473684, "f1": 0.1702127659574468}, "Used_for": {"precision": 0.2611683848797251, "recall": 0.1425891181988743, "f1": 0.18446601941747573}, "Conjunction": {"precision": 0.4, "recall": 0.06504065040650407, "f1": 0.11188811188811189}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0.3684210526315789, "recall": 0.1044776119402985, "f1": 0.1627906976744186}, "Evaluate_for": {"precision": 0.4, "recall": 0.02197802197802198, "f1": 0.04166666666666668}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-02-09-28", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]