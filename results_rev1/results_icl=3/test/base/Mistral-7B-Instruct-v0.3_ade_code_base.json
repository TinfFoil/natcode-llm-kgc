[{"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.3516819571865443, "Recall": 0.26018099547511314, "F1_Score": 0.29908972691807545, "rel_type_metrics": {"Adverse_effect": {"precision": 0.4872881355932203, "recall": 0.26018099547511314, "f1": 0.3392330383480826}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-14-26-46", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.3554987212276215, "Recall": 0.31447963800904977, "F1_Score": 0.33373349339735897, "rel_type_metrics": {"Adverse_effect": {"precision": 0.4384858044164038, "recall": 0.31447963800904977, "f1": 0.3662714097496706}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-14-30-31", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": false, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.3538961038961039, "Recall": 0.24660633484162897, "F1_Score": 0.29066666666666663, "rel_type_metrics": {"Adverse_effect": {"precision": 0.42412451361867703, "recall": 0.24660633484162897, "f1": 0.31187410586552217}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-14-33-49", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": false, "chat_model": true}]