[{"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.07571801566579635, "Recall": 0.06561085972850679, "F1_Score": 0.07030303030303031, "rel_type_metrics": {"Adverse_effect": {"precision": 0.27884615384615385, "recall": 0.06561085972850679, "f1": 0.10622710622710624}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-28-15-09-56", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.04112554112554113, "Recall": 0.042986425339366516, "F1_Score": 0.04203539823008849, "rel_type_metrics": {"Adverse_effect": {"precision": 0.14393939393939395, "recall": 0.042986425339366516, "f1": 0.0662020905923345}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-02-14-51", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "Qwen/CodeQwen1.5-7B-Chat", "Precision": 0.06912442396313365, "Recall": 0.06787330316742081, "F1_Score": 0.0684931506849315, "rel_type_metrics": {"Adverse_effect": {"precision": 0.22900763358778625, "recall": 0.06787330316742081, "f1": 0.10471204188481675}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-02-20-09", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}]