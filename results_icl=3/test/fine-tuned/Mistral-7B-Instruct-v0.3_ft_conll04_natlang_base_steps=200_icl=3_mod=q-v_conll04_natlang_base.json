[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_base_steps=200_icl=3_mod=q-v", "Precision": 0.6433915211970075, "Recall": 0.6339066339066339, "F1_Score": 0.6386138613861386, "rel_type_metrics": {"Live_in": {"precision": 0.6704545454545454, "recall": 0.6020408163265306, "f1": 0.6344086021505377}, "Work_for": {"precision": 0.5340909090909091, "recall": 0.618421052631579, "f1": 0.5731707317073171}, "Located_in": {"precision": 0.6428571428571429, "recall": 0.6, "f1": 0.6206896551724138}, "Kill": {"precision": 0.8958333333333334, "recall": 0.9148936170212766, "f1": 0.9052631578947369}, "Organization_based_in": {"precision": 0.5913978494623656, "recall": 0.5729166666666666, "f1": 0.5820105820105821}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-31-21", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_base_steps=200_icl=3_mod=q-v", "Precision": 0.6736842105263158, "Recall": 0.628992628992629, "F1_Score": 0.650571791613723, "rel_type_metrics": {"Organization_based_in": {"precision": 0.6712328767123288, "recall": 0.5104166666666666, "f1": 0.5798816568047337}, "Kill": {"precision": 0.8979591836734694, "recall": 0.9361702127659575, "f1": 0.9166666666666666}, "Located_in": {"precision": 0.6790123456790124, "recall": 0.6111111111111112, "f1": 0.6432748538011697}, "Live_in": {"precision": 0.7037037037037037, "recall": 0.5816326530612245, "f1": 0.6368715083798882}, "Work_for": {"precision": 0.53125, "recall": 0.6710526315789473, "f1": 0.5930232558139534}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-33-26", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_base_steps=200_icl=3_mod=q-v", "Precision": 0.633495145631068, "Recall": 0.6412776412776413, "F1_Score": 0.6373626373626374, "rel_type_metrics": {"Live_in": {"precision": 0.6923076923076923, "recall": 0.6428571428571429, "f1": 0.6666666666666666}, "Located_in": {"precision": 0.627906976744186, "recall": 0.6, "f1": 0.6136363636363636}, "Organization_based_in": {"precision": 0.6363636363636364, "recall": 0.5104166666666666, "f1": 0.5664739884393063}, "Kill": {"precision": 0.8627450980392157, "recall": 0.9361702127659575, "f1": 0.8979591836734694}, "Work_for": {"precision": 0.4766355140186916, "recall": 0.6710526315789473, "f1": 0.5573770491803279}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-35-35", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": true}]