[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_rationale_steps=200_icl=3_mod=q-v", "Precision": 0.6573816155988857, "Recall": 0.5798525798525799, "F1_Score": 0.6161879895561357, "rel_type_metrics": {"Work_for": {"precision": 0.5833333333333334, "recall": 0.5526315789473685, "f1": 0.5675675675675677}, "Organization_based_in": {"precision": 0.5789473684210527, "recall": 0.4583333333333333, "f1": 0.5116279069767442}, "Kill": {"precision": 0.851063829787234, "recall": 0.851063829787234, "f1": 0.8510638297872339}, "Located_in": {"precision": 0.6835443037974683, "recall": 0.6, "f1": 0.6390532544378698}, "Live_in": {"precision": 0.6829268292682927, "recall": 0.5714285714285714, "f1": 0.6222222222222223}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-17-08-44", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_rationale_steps=200_icl=3_mod=q-v", "Precision": 0.6620111731843575, "Recall": 0.5823095823095823, "F1_Score": 0.6196078431372548, "rel_type_metrics": {"Work_for": {"precision": 0.5844155844155844, "recall": 0.5921052631578947, "f1": 0.5882352941176471}, "Located_in": {"precision": 0.6666666666666666, "recall": 0.5777777777777777, "f1": 0.619047619047619}, "Live_in": {"precision": 0.6292134831460674, "recall": 0.5714285714285714, "f1": 0.5989304812834225}, "Kill": {"precision": 0.84, "recall": 0.8936170212765957, "f1": 0.8659793814432989}, "Organization_based_in": {"precision": 0.65625, "recall": 0.4375, "f1": 0.525}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-17-11-55", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_rationale_steps=200_icl=3_mod=q-v", "Precision": 0.649867374005305, "Recall": 0.601965601965602, "F1_Score": 0.625, "rel_type_metrics": {"Kill": {"precision": 0.5063291139240507, "recall": 0.851063829787234, "f1": 0.634920634920635}, "Live_in": {"precision": 0.6588235294117647, "recall": 0.5714285714285714, "f1": 0.6120218579234972}, "Located_in": {"precision": 0.7142857142857143, "recall": 0.6111111111111112, "f1": 0.6586826347305389}, "Work_for": {"precision": 0.6666666666666666, "recall": 0.6052631578947368, "f1": 0.6344827586206896}, "Organization_based_in": {"precision": 0.7384615384615385, "recall": 0.5, "f1": 0.5962732919254659}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-17-17-00", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]