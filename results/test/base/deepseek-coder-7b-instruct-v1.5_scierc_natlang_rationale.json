[{"Model": "deepseek-ai/deepseek-coder-7b-instruct-v1.5", "Precision": 0.0624512099921936, "Recall": 0.0624512099921936, "F1_Score": 0.0624512099921936, "rel_type_metrics": {"Feature_of": {"prec": 0.037383177570093455, "rec": 0.04, "f1": 0.03864734299516908}, "Evaluate_for": {"prec": 0.03225806451612903, "rec": 0.03164556962025317, "f1": 0.03194888178913738}, "Hyponym_of": {"prec": 0.06109324758842444, "rec": 0.05397727272727273, "f1": 0.05731523378582202}, "Used_for": {"prec": 0.08995265649658074, "rec": 0.09799426934097422, "f1": 0.09380142622051563}, "Conjunction": {"prec": 0.08029197080291971, "rec": 0.06984126984126984, "f1": 0.07470288624787777}, "Compare": {"prec": 0.056451612903225805, "rec": 0.05785123966942149, "f1": 0.05714285714285714}, "Part_of": {"prec": 0.04932735426008968, "rec": 0.046218487394957986, "f1": 0.04772234273318872}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-23-16-08-43", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}]