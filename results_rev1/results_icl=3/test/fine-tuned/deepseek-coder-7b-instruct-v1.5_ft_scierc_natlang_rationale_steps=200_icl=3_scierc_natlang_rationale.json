[{"Model": "./models/deepseek-coder-7b-instruct-v1.5_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.2086720867208672, "Recall": 0.15811088295687886, "F1_Score": 0.1799065420560748, "rel_type_metrics": {"Hyponym_of": {"precision": 0.375, "recall": 0.08955223880597014, "f1": 0.14457831325301204}, "Part_of": {"precision": 0.3333333333333333, "recall": 0.015873015873015872, "f1": 0.030303030303030304}, "Compare": {"precision": 0.3157894736842105, "recall": 0.3157894736842105, "f1": 0.3157894736842105}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.2, "recall": 0.032520325203252036, "f1": 0.055944055944055944}, "Used_for": {"precision": 0.21087314662273476, "recall": 0.2401500938086304, "f1": 0.22456140350877193}, "Evaluate_for": {"precision": 0.25, "recall": 0.03296703296703297, "f1": 0.05825242718446602}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-26-21-10-16", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/deepseek-coder-7b-instruct-v1.5_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.20077720207253885, "Recall": 0.1591375770020534, "F1_Score": 0.1775486827033219, "rel_type_metrics": {"Evaluate_for": {"precision": 0.6666666666666666, "recall": 0.04395604395604396, "f1": 0.08247422680412372}, "Compare": {"precision": 0.3333333333333333, "recall": 0.34210526315789475, "f1": 0.33766233766233766}, "Used_for": {"precision": 0.2, "recall": 0.24390243902439024, "f1": 0.21978021978021978}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0.4444444444444444, "recall": 0.05970149253731343, "f1": 0.10526315789473685}, "Conjunction": {"precision": 0.2, "recall": 0.024390243902439025, "f1": 0.04347826086956522}, "Part_of": {"precision": 0.16666666666666666, "recall": 0.015873015873015872, "f1": 0.028985507246376812}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-28-14-52-45", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/deepseek-coder-7b-instruct-v1.5_ft_scierc_natlang_rationale_steps=200_icl=3", "Precision": 0.21282401091405184, "Recall": 0.1601642710472279, "F1_Score": 0.18277680140597538, "rel_type_metrics": {"Hyponym_of": {"precision": 0.3333333333333333, "recall": 0.07462686567164178, "f1": 0.12195121951219512}, "Compare": {"precision": 0.3333333333333333, "recall": 0.2894736842105263, "f1": 0.3098591549295775}, "Evaluate_for": {"precision": 0.5555555555555556, "recall": 0.054945054945054944, "f1": 0.1}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Part_of": {"precision": 0.25, "recall": 0.015873015873015872, "f1": 0.029850746268656716}, "Used_for": {"precision": 0.20930232558139536, "recall": 0.23639774859287055, "f1": 0.22202643171806166}, "Conjunction": {"precision": 0.3076923076923077, "recall": 0.06504065040650407, "f1": 0.10738255033557048}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-01-51-18", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]