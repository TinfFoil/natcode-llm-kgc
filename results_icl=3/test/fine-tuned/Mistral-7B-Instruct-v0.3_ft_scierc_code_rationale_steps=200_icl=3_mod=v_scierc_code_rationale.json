[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=v", "Precision": 0.265695067264574, "Recall": 0.2433264887063655, "F1_Score": 0.2540192926045016, "rel_type_metrics": {"Conjunction": {"precision": 0.36666666666666664, "recall": 0.2682926829268293, "f1": 0.30985915492957744}, "Evaluate_for": {"precision": 0.18446601941747573, "recall": 0.2087912087912088, "f1": 0.1958762886597938}, "Part_of": {"precision": 0.2, "recall": 0.09523809523809523, "f1": 0.12903225806451613}, "Used_for": {"precision": 0.26480263157894735, "recall": 0.30206378986866794, "f1": 0.2822085889570552}, "Compare": {"precision": 0.3235294117647059, "recall": 0.2894736842105263, "f1": 0.30555555555555564}, "Feature_of": {"precision": 0.1111111111111111, "recall": 0.01694915254237288, "f1": 0.02941176470588235}, "Hyponym_of": {"precision": 0.375, "recall": 0.08955223880597014, "f1": 0.14457831325301204}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-19-46-41", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=v", "Precision": 0.2855392156862745, "Recall": 0.23921971252566734, "F1_Score": 0.26033519553072626, "rel_type_metrics": {"Used_for": {"precision": 0.2980599647266314, "recall": 0.3170731707317073, "f1": 0.30727272727272725}, "Evaluate_for": {"precision": 0.23333333333333334, "recall": 0.15384615384615385, "f1": 0.18543046357615894}, "Hyponym_of": {"precision": 0.3157894736842105, "recall": 0.08955223880597014, "f1": 0.13953488372093023}, "Part_of": {"precision": 0.16666666666666666, "recall": 0.047619047619047616, "f1": 0.07407407407407407}, "Compare": {"precision": 0.20588235294117646, "recall": 0.18421052631578946, "f1": 0.19444444444444445}, "Conjunction": {"precision": 0.32978723404255317, "recall": 0.25203252032520324, "f1": 0.2857142857142857}, "Feature_of": {"precision": 0.15789473684210525, "recall": 0.05084745762711865, "f1": 0.07692307692307693}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-20-08-42", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_scierc_code_rationale_steps=200_icl=3_mod=v", "Precision": 0.2748868778280543, "Recall": 0.24948665297741274, "F1_Score": 0.2615715823466092, "rel_type_metrics": {"Hyponym_of": {"precision": 0.2727272727272727, "recall": 0.04477611940298507, "f1": 0.07692307692307691}, "Part_of": {"precision": 0.16666666666666666, "recall": 0.06349206349206349, "f1": 0.09195402298850575}, "Used_for": {"precision": 0.29180327868852457, "recall": 0.3339587242026266, "f1": 0.3114610673665791}, "Evaluate_for": {"precision": 0.1935483870967742, "recall": 0.1978021978021978, "f1": 0.19565217391304346}, "Compare": {"precision": 0.25, "recall": 0.2631578947368421, "f1": 0.25641025641025644}, "Conjunction": {"precision": 0.28865979381443296, "recall": 0.22764227642276422, "f1": 0.2545454545454545}, "Feature_of": {"precision": 0.25, "recall": 0.03389830508474576, "f1": 0.05970149253731343}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2025-03-31-20-28-58", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": true}]