[{"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.1322314049586777, "Recall": 0.2171945701357466, "F1_Score": 0.16438356164383564, "rel_type_metrics": {"Adverse_effect": {"precision": 0.26666666666666666, "recall": 0.2171945701357466, "f1": 0.23940149625935164}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-10-50-34", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.17105263157894737, "Recall": 0.23529411764705882, "F1_Score": 0.19809523809523807, "rel_type_metrics": {"Adverse_effect": {"precision": 0.5333333333333333, "recall": 0.23529411764705882, "f1": 0.326530612244898}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-10-51-54", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "mistralai/Mistral-7B-Instruct-v0.3", "Precision": 0.2956989247311828, "Recall": 0.3733031674208145, "F1_Score": 0.33000000000000007, "rel_type_metrics": {"Adverse_effect": {"precision": 0.4881656804733728, "recall": 0.3733031674208145, "f1": 0.42307692307692313}}, "n_icl_samples": 3, "n_samples_test": 300, "dataset": "ade", "date": "2024-12-29-10-53-16", "schema_path": "./data/codekgc-data/ade/code_prompt", "split": "test", "fine-tuned": false, "rationale": false, "natlang": true, "chat_model": true}]