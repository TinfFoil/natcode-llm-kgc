[{"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_base_steps=200_icl=3_mod=q-k-v", "Precision": 0.6376470588235295, "Recall": 0.6658476658476659, "F1_Score": 0.6514423076923078, "rel_type_metrics": {"Kill": {"precision": 0.7241379310344828, "recall": 0.8936170212765957, "f1": 0.7999999999999999}, "Located_in": {"precision": 0.6506024096385542, "recall": 0.6, "f1": 0.6242774566473989}, "Organization_based_in": {"precision": 0.5625, "recall": 0.65625, "f1": 0.6057692307692307}, "Work_for": {"precision": 0.6533333333333333, "recall": 0.6447368421052632, "f1": 0.6490066225165563}, "Live_in": {"precision": 0.6631578947368421, "recall": 0.6428571428571429, "f1": 0.6528497409326425}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-34-08", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_base_steps=200_icl=3_mod=q-k-v", "Precision": 0.629976580796253, "Recall": 0.6609336609336609, "F1_Score": 0.645083932853717, "rel_type_metrics": {"Kill": {"precision": 0.7777777777777778, "recall": 0.8936170212765957, "f1": 0.8316831683168316}, "Live_in": {"precision": 0.5980392156862745, "recall": 0.6224489795918368, "f1": 0.61}, "Located_in": {"precision": 0.6588235294117647, "recall": 0.6222222222222222, "f1": 0.64}, "Work_for": {"precision": 0.6538461538461539, "recall": 0.6710526315789473, "f1": 0.6623376623376623}, "Organization_based_in": {"precision": 0.5619047619047619, "recall": 0.6145833333333334, "f1": 0.5870646766169154}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-36-24", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": true}, {"Model": "./models/Mistral-7B-Instruct-v0.3_ft_conll04_natlang_base_steps=200_icl=3_mod=q-k-v", "Precision": 0.6141176470588235, "Recall": 0.6412776412776413, "F1_Score": 0.6274038461538461, "rel_type_metrics": {"Organization_based_in": {"precision": 0.5188679245283019, "recall": 0.5729166666666666, "f1": 0.5445544554455445}, "Located_in": {"precision": 0.654320987654321, "recall": 0.5888888888888889, "f1": 0.6198830409356726}, "Work_for": {"precision": 0.6024096385542169, "recall": 0.6578947368421053, "f1": 0.628930817610063}, "Kill": {"precision": 0.75, "recall": 0.8936170212765957, "f1": 0.8155339805825244}, "Live_in": {"precision": 0.6288659793814433, "recall": 0.6224489795918368, "f1": 0.6256410256410256}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2025-03-31-18-39-15", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": true, "chat_model": true}]