[{"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.27450980392156865, "Recall": 0.1375921375921376, "F1_Score": 0.1833060556464812, "rel_type_metrics": {"Live_in": {"precision": 0.08888888888888889, "recall": 0.08163265306122448, "f1": 0.0851063829787234}, "Organization_based_in": {"precision": 0.358974358974359, "recall": 0.14583333333333334, "f1": 0.20740740740740743}, "Kill": {"precision": 0.5, "recall": 0.0425531914893617, "f1": 0.0784313725490196}, "Located_in": {"precision": 0.3469387755102041, "recall": 0.18888888888888888, "f1": 0.2446043165467626}, "Work_for": {"precision": 0.75, "recall": 0.19736842105263158, "f1": 0.31249999999999994}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-26-21-22-00", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.18238993710691823, "Recall": 0.07125307125307126, "F1_Score": 0.10247349823321555, "rel_type_metrics": {"Work_for": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Live_in": {"precision": 0.2, "recall": 0.02040816326530612, "f1": 0.03703703703703703}, "Kill": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Located_in": {"precision": 0.4117647058823529, "recall": 0.15555555555555556, "f1": 0.22580645161290322}, "Organization_based_in": {"precision": 0.5, "recall": 0.13541666666666666, "f1": 0.21311475409836064}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-15-04-57", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "./models/Meta-Llama-3.1-8B-Instruct_ft_conll04_natlang_rationale_steps=200_icl=3", "Precision": 0.2605633802816901, "Recall": 0.09090909090909091, "F1_Score": 0.13479052823315116, "rel_type_metrics": {"Work_for": {"precision": 0.7142857142857143, "recall": 0.06578947368421052, "f1": 0.12048192771084337}, "Kill": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Live_in": {"precision": 0.06060606060606061, "recall": 0.04081632653061224, "f1": 0.04878048780487805}, "Organization_based_in": {"precision": 0.3793103448275862, "recall": 0.11458333333333333, "f1": 0.17600000000000002}, "Located_in": {"precision": 0.4722222222222222, "recall": 0.18888888888888888, "f1": 0.2698412698412698}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-02-08-16", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": true}]