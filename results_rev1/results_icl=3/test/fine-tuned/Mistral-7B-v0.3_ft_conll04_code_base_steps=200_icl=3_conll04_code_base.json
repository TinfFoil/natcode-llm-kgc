[{"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.6152173913043478, "Recall": 0.6953316953316954, "F1_Score": 0.6528258362168397, "rel_type_metrics": {"Work_for": {"precision": 0.7352941176470589, "recall": 0.6578947368421053, "f1": 0.6944444444444445}, "Located_in": {"precision": 0.62, "recall": 0.6888888888888889, "f1": 0.6526315789473685}, "Organization_based_in": {"precision": 0.44696969696969696, "recall": 0.6145833333333334, "f1": 0.5175438596491229}, "Kill": {"precision": 0.8936170212765957, "recall": 0.8936170212765957, "f1": 0.8936170212765957}, "Live_in": {"precision": 0.6194690265486725, "recall": 0.7142857142857143, "f1": 0.6635071090047393}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-27-01-52-02", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.6087912087912087, "Recall": 0.6805896805896806, "F1_Score": 0.642691415313225, "rel_type_metrics": {"Organization_based_in": {"precision": 0.6333333333333333, "recall": 0.59375, "f1": 0.6129032258064516}, "Kill": {"precision": 0.8367346938775511, "recall": 0.8723404255319149, "f1": 0.8541666666666667}, "Work_for": {"precision": 0.6923076923076923, "recall": 0.5921052631578947, "f1": 0.6382978723404255}, "Live_in": {"precision": 0.6634615384615384, "recall": 0.7040816326530612, "f1": 0.6831683168316831}, "Located_in": {"precision": 0.4421768707482993, "recall": 0.7222222222222222, "f1": 0.5485232067510548}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-28-20-57-07", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_base_steps=200_icl=3", "Precision": 0.6065217391304348, "Recall": 0.6855036855036855, "F1_Score": 0.643598615916955, "rel_type_metrics": {"Located_in": {"precision": 0.6526315789473685, "recall": 0.6888888888888889, "f1": 0.6702702702702703}, "Live_in": {"precision": 0.72, "recall": 0.7346938775510204, "f1": 0.7272727272727272}, "Work_for": {"precision": 0.3712121212121212, "recall": 0.6447368421052632, "f1": 0.47115384615384615}, "Organization_based_in": {"precision": 0.6395348837209303, "recall": 0.5729166666666666, "f1": 0.6043956043956044}, "Kill": {"precision": 0.8723404255319149, "recall": 0.8723404255319149, "f1": 0.8723404255319149}}, "n_icl_samples": 3, "n_samples_test": 288, "dataset": "conll04", "date": "2024-12-29-11-13-05", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": false, "natlang": false, "chat_model": false}]