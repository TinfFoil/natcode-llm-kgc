[{"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_rationale_steps=200_icl=0", "Precision": 0.7361111111111112, "Recall": 0.5208845208845209, "F1_Score": 0.6100719424460431, "rel_type_metrics": {"Work_for": {"precision": 0.7037037037037037, "recall": 0.5, "f1": 0.5846153846153846}, "Located_in": {"precision": 0.7857142857142857, "recall": 0.36666666666666664, "f1": 0.5}, "Live_in": {"precision": 0.6875, "recall": 0.5612244897959183, "f1": 0.6179775280898877}, "Kill": {"precision": 0.8541666666666666, "recall": 0.8723404255319149, "f1": 0.8631578947368421}, "Organization_based_in": {"precision": 0.703125, "recall": 0.46875, "f1": 0.5625}}, "n_icl_samples": 0, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-18-00-55-57", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_rationale_steps=200_icl=0", "Precision": 0.7395833333333334, "Recall": 0.5233415233415234, "F1_Score": 0.6129496402877698, "rel_type_metrics": {"Work_for": {"precision": 0.6981132075471698, "recall": 0.4868421052631579, "f1": 0.5736434108527132}, "Located_in": {"precision": 0.7906976744186046, "recall": 0.37777777777777777, "f1": 0.5112781954887218}, "Organization_based_in": {"precision": 0.6923076923076923, "recall": 0.46875, "f1": 0.5590062111801243}, "Kill": {"precision": 0.875, "recall": 0.8936170212765957, "f1": 0.8842105263157894}, "Live_in": {"precision": 0.6962025316455697, "recall": 0.5612244897959183, "f1": 0.6214689265536724}}, "n_icl_samples": 0, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-18-00-58-57", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_conll04_code_rationale_steps=200_icl=0", "Precision": 0.7361111111111112, "Recall": 0.5208845208845209, "F1_Score": 0.6100719424460431, "rel_type_metrics": {"Live_in": {"precision": 0.7, "recall": 0.5714285714285714, "f1": 0.6292134831460674}, "Organization_based_in": {"precision": 0.6923076923076923, "recall": 0.46875, "f1": 0.5590062111801243}, "Located_in": {"precision": 0.7857142857142857, "recall": 0.36666666666666664, "f1": 0.5}, "Kill": {"precision": 0.8541666666666666, "recall": 0.8723404255319149, "f1": 0.8631578947368421}, "Work_for": {"precision": 0.6981132075471698, "recall": 0.4868421052631579, "f1": 0.5736434108527132}}, "n_icl_samples": 0, "n_samples_test": 288, "dataset": "conll04", "date": "2025-01-18-01-02-02", "schema_path": "./data/codekgc-data/conll04/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]