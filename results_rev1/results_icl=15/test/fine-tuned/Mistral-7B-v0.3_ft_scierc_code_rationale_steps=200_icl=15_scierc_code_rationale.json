[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=15", "Precision": 0.321025641025641, "Recall": 0.3213552361396304, "F1_Score": 0.3211903540277065, "rel_type_metrics": {"Part_of": {"precision": 0.20634920634920634, "recall": 0.20634920634920634, "f1": 0.20634920634920634}, "Compare": {"precision": 0.34782608695652173, "recall": 0.42105263157894735, "f1": 0.380952380952381}, "Hyponym_of": {"precision": 0.47619047619047616, "recall": 0.44776119402985076, "f1": 0.4615384615384615}, "Used_for": {"precision": 0.3626609442060086, "recall": 0.3170731707317073, "f1": 0.3383383383383384}, "Conjunction": {"precision": 0.32903225806451614, "recall": 0.4146341463414634, "f1": 0.3669064748201439}, "Feature_of": {"precision": 0.028985507246376812, "recall": 0.03389830508474576, "f1": 0.03125}, "Evaluate_for": {"precision": 0.2831858407079646, "recall": 0.3516483516483517, "f1": 0.3137254901960784}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-21-42-27", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=15", "Precision": 0.33049946865037194, "Recall": 0.3193018480492813, "F1_Score": 0.3248041775456919, "rel_type_metrics": {"Part_of": {"precision": 0.20987654320987653, "recall": 0.2698412698412698, "f1": 0.23611111111111108}, "Used_for": {"precision": 0.3686534216335541, "recall": 0.3133208255159475, "f1": 0.33874239350912777}, "Compare": {"precision": 0.32608695652173914, "recall": 0.39473684210526316, "f1": 0.35714285714285715}, "Conjunction": {"precision": 0.3262411347517731, "recall": 0.37398373983739835, "f1": 0.34848484848484845}, "Feature_of": {"precision": 0.08196721311475409, "recall": 0.0847457627118644, "f1": 0.08333333333333333}, "Evaluate_for": {"precision": 0.34545454545454546, "recall": 0.4175824175824176, "f1": 0.37810945273631835}, "Hyponym_of": {"precision": 0.46938775510204084, "recall": 0.34328358208955223, "f1": 0.3965517241379311}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-02-35", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_code_rationale_steps=200_icl=15", "Precision": 0.3311331133113311, "Recall": 0.30903490759753593, "F1_Score": 0.31970260223048325, "rel_type_metrics": {"Hyponym_of": {"precision": 0.5, "recall": 0.373134328358209, "f1": 0.4273504273504274}, "Feature_of": {"precision": 0.017543859649122806, "recall": 0.01694915254237288, "f1": 0.017241379310344827}, "Conjunction": {"precision": 0.30985915492957744, "recall": 0.35772357723577236, "f1": 0.3320754716981132}, "Evaluate_for": {"precision": 0.3090909090909091, "recall": 0.37362637362637363, "f1": 0.33830845771144274}, "Part_of": {"precision": 0.2537313432835821, "recall": 0.2698412698412698, "f1": 0.26153846153846155}, "Used_for": {"precision": 0.37844036697247707, "recall": 0.30956848030018763, "f1": 0.3405572755417957}, "Compare": {"precision": 0.3191489361702128, "recall": 0.39473684210526316, "f1": 0.3529411764705882}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-22-21-46", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": false, "chat_model": false}]