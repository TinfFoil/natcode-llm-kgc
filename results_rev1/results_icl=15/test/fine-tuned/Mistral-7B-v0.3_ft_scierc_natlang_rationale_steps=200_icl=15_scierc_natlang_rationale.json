[{"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=15", "Precision": 0.35066505441354295, "Recall": 0.29774127310061604, "F1_Score": 0.32204330927262637, "rel_type_metrics": {"Compare": {"precision": 0.3695652173913043, "recall": 0.4473684210526316, "f1": 0.40476190476190477}, "Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0.4222222222222222, "recall": 0.2835820895522388, "f1": 0.3392857142857143}, "Conjunction": {"precision": 0.3963963963963964, "recall": 0.35772357723577236, "f1": 0.37606837606837606}, "Used_for": {"precision": 0.38425925925925924, "recall": 0.31144465290806755, "f1": 0.3440414507772021}, "Part_of": {"precision": 0.16666666666666666, "recall": 0.12698412698412698, "f1": 0.14414414414414417}, "Evaluate_for": {"precision": 0.32142857142857145, "recall": 0.3956043956043956, "f1": 0.35467980295566504}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-32-37", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=15", "Precision": 0.3431818181818182, "Recall": 0.31006160164271046, "F1_Score": 0.325782092772384, "rel_type_metrics": {"Feature_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0.30303030303030304, "recall": 0.43956043956043955, "f1": 0.3587443946188341}, "Used_for": {"precision": 0.38215102974828374, "recall": 0.3133208255159475, "f1": 0.34432989690721655}, "Part_of": {"precision": 0.17543859649122806, "recall": 0.15873015873015872, "f1": 0.16666666666666666}, "Conjunction": {"precision": 0.3888888888888889, "recall": 0.3983739837398374, "f1": 0.39357429718875503}, "Compare": {"precision": 0.30612244897959184, "recall": 0.39473684210526316, "f1": 0.3448275862068966}, "Hyponym_of": {"precision": 0.5, "recall": 0.31343283582089554, "f1": 0.3853211009174312}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-42-12", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}, {"Model": "./models/Mistral-7B-v0.3_ft_scierc_natlang_rationale_steps=200_icl=15", "Precision": 0.34269662921348315, "Recall": 0.3131416837782341, "F1_Score": 0.3272532188841202, "rel_type_metrics": {"Evaluate_for": {"precision": 0.2835820895522388, "recall": 0.4175824175824176, "f1": 0.3377777777777778}, "Part_of": {"precision": 0.17307692307692307, "recall": 0.14285714285714285, "f1": 0.1565217391304348}, "Hyponym_of": {"precision": 0.4418604651162791, "recall": 0.2835820895522388, "f1": 0.3454545454545454}, "Compare": {"precision": 0.3, "recall": 0.39473684210526316, "f1": 0.34090909090909094}, "Feature_of": {"precision": 0.02857142857142857, "recall": 0.01694915254237288, "f1": 0.02127659574468085}, "Used_for": {"precision": 0.38990825688073394, "recall": 0.31894934333958724, "f1": 0.3508771929824561}, "Conjunction": {"precision": 0.38686131386861317, "recall": 0.43089430894308944, "f1": 0.4076923076923077}}, "n_icl_samples": 15, "n_samples_test": 397, "dataset": "scierc", "date": "2025-01-18-18-52-23", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": true, "rationale": true, "natlang": true, "chat_model": false}]