[{"Model": "unsloth/Meta-Llama-3.1-8B-Instruct", "Precision": 0.0612061206120612, "Recall": 0.06981519507186858, "F1_Score": 0.06522781774580336, "rel_type_metrics": {"Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0.03508771929824561, "recall": 0.05263157894736842, "f1": 0.042105263157894736}, "Part_of": {"precision": 0.02072538860103627, "recall": 0.06349206349206349, "f1": 0.03125}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0.18032786885245902, "recall": 0.16417910447761194, "f1": 0.171875}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.1624203821656051, "recall": 0.09568480300187618, "f1": 0.12042502951593861}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-26-21-29-02", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-8B-Instruct", "Precision": 0.0945945945945946, "Recall": 0.11498973305954825, "F1_Score": 0.10379981464318813, "rel_type_metrics": {"Part_of": {"precision": 0.0, "recall": 0.0, "f1": 0}, "Hyponym_of": {"precision": 0.07792207792207792, "recall": 0.1791044776119403, "f1": 0.1085972850678733}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0, "recall": 0.0, "f1": 0}, "Compare": {"precision": 0.11627906976744186, "recall": 0.2631578947368421, "f1": 0.16129032258064516}, "Used_for": {"precision": 0.1070154577883472, "recall": 0.16885553470919323, "f1": 0.13100436681222707}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-28-15-28-00", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}, {"Model": "unsloth/Meta-Llama-3.1-8B-Instruct", "Precision": 0.09586466165413533, "Recall": 0.10472279260780287, "F1_Score": 0.1000981354268891, "rel_type_metrics": {"Compare": {"precision": 0, "recall": 0.0, "f1": 0}, "Feature_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Conjunction": {"precision": 0.10526315789473684, "recall": 0.032520325203252036, "f1": 0.049689440993788817}, "Hyponym_of": {"precision": 0, "recall": 0.0, "f1": 0}, "Evaluate_for": {"precision": 0, "recall": 0.0, "f1": 0}, "Used_for": {"precision": 0.1206896551724138, "recall": 0.17073170731707318, "f1": 0.14141414141414144}, "Part_of": {"precision": 0.04093567251461988, "recall": 0.1111111111111111, "f1": 0.05982905982905983}}, "n_icl_samples": 3, "n_samples_test": 397, "dataset": "scierc", "date": "2024-12-29-02-53-12", "schema_path": "./data/codekgc-data/scierc/code_prompt", "split": "test", "fine-tuned": false, "rationale": true, "natlang": true, "chat_model": true}]